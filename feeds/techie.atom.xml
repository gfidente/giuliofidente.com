<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Giulio Fidente (aka Giulivo Navigante)</title><link href="http://www.giuliofidente.com/" rel="alternate"></link><link href="http://www.giuliofidente.com/feeds/techie.atom.xml" rel="self"></link><id>http://www.giuliofidente.com/</id><updated>2013-04-15T00:00:00+02:00</updated><entry><title>Deploy OpenStack Heat on RHEL (and derivates)</title><link href="http://www.giuliofidente.com/2013/04/deploy-openstack-heat-on-rhel-and-derivates.html" rel="alternate"></link><updated>2013-04-15T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2013-04-15:2013/04/deploy-openstack-heat-on-rhel-and-derivates.html</id><summary type="html">&lt;p&gt;&lt;a class="reference external" href="http://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt; provides orchestration of composite cloud applications using the CloudFormation API and templates; it is an incubated project of &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt;. Its development cycle has been integrated with &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; from the H release and, with the recent G release, it's got more mature. I want to go trough the steps needed to install and configure it as the &lt;a class="reference external" href="http://docs.openstack.org"&gt;official documentation&lt;/a&gt; is still scarce on the matter. Firstly, what it does?&lt;/p&gt;
&lt;blockquote&gt;
Heat is a service to orchestrate multiple composite cloud applications using the AWS CloudFormation template format, through both an OpenStack-native ReST API and a CloudFormation-compatible Query API.&lt;/blockquote&gt;
&lt;p&gt;So you're going to deploy a composite application (made up of more than a single instance) on the cloud infrastructure, this also involves launchtime customizations of the VMs but before start, some assumptions are needed:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;I'm using CentOS 6.4 / MySQL for the examples&lt;/li&gt;
&lt;li&gt;I'm using the &lt;a class="reference external" href="http://openstack.redhat.com"&gt;RDO&lt;/a&gt; repository to install the packages&lt;/li&gt;
&lt;li&gt;The core &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; infrastructure is already configured and in good shape&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="installation"&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;If you don't have a working &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; deployment yet, I recommend you to simply follow the instructions on the &lt;a class="reference external" href="http://openstack.redhat.com"&gt;RDO&lt;/a&gt; site. You'll get one up and running in minutes using &lt;a class="reference external" href="http://wiki.openstack.org/Packstack"&gt;Packstack&lt;/a&gt;. When that is done, start by installing the required packages for &lt;a class="reference external" href="http://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt; to work:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# yum install openstack-heat-*
&lt;/pre&gt;
&lt;p&gt;You'll get four new services installed: an engine, a native api, a cloudformation compatible api, a cloudwatch compatible api. You don't have to deploy them all on a single host but for the purpose of this guide it will be fine to do so.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="configuration"&gt;
&lt;h2&gt;Configuration&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt; comes with a script which creates (and populates) the needed database for it to work. You'll need to know the MySQL's &lt;code&gt;root&lt;/code&gt; account password. If you've used &lt;a class="reference external" href="http://wiki.openstack.org/Packstack"&gt;Packstack&lt;/a&gt; that is stored as &lt;code&gt;CONFIG_MYSQL_PW&lt;/code&gt; in the answers file at &lt;code&gt;/root/packstack-answers*&lt;/code&gt; file. When you've collected it, run the prepare script:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# heat-db-setup rpm -y -r ${MYSQL_ROOT_PASSWORD} -p ${HEAT_DB_PASSWORD_OF_CHOICE}
&lt;/pre&gt;
&lt;p&gt;Check in &lt;code&gt;/etc/heat/heat-engine.conf&lt;/code&gt; that your database connection string is correct:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sql_connection = mysql://heat:${HEAT_DB_PASSWORD}&amp;#64;localhost/heat
&lt;/pre&gt;
&lt;p&gt;Now go trough the &lt;em&gt;usual&lt;/em&gt; steps needed to create a new user, service and endpoint with Keystone and don't forget to source the admin credentials before starting (which are in &lt;code&gt;/root/keystonerc_admin&lt;/code&gt; if you've used &lt;a class="reference external" href="http://wiki.openstack.org/Packstack"&gt;Packstack&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# keystone user-create --name heat --pass ${HEAT_USER_PASSWORD_OF_CHOICE}
# keystone user-role-add --user heat --role admin --tenant ${SERVICES_TENANT_NAME}
# keystone service-create --name heat --type orchestration
# keystone service-create --name heat-cfn --type cloudformation
# keystone endpoint-create --region RegionOne --service-id ${HEAT-CFN-SERVICE-ID} --publicurl &amp;quot;http://${HEAT-CFN-HOSTNAME}:8000/v1&amp;quot; --adminurl &amp;quot;http://${HEAT-CFN-HOSTNAME}:8000/v1&amp;quot; --internalurl &amp;quot;http://${HEAT-CFN-HOSTNAME}:8000/v1&amp;quot;
# keystone endpoint-create --region RegionOne --service-id ${HEAT-SERVICE-ID} --publicurl &amp;quot;http://${HEAT-HOSTNAME}:8004/v1/%(tenant_id)s&amp;quot; --adminurl &amp;quot;http://${HEAT-HOSTNAME}:8004/v1/%(tenant_id)s --internalurl &amp;quot;http://${HEAT-HOSTNAME}:8004/v1/%(tenant_id)s&amp;quot;
&lt;/pre&gt;
&lt;p&gt;Update the paste files at &lt;code&gt;/etc/heat/heat-api{,-cfn,-cloudwatch}-paste.ini&lt;/code&gt; with the credentials just created:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
admin_tenant_name = services
admin_user = heat
admin_password = ${HEAT_USER_PASSWORD}
&lt;/pre&gt;
&lt;p&gt;In there you also need to make sure that the following variables are pointing to your Keystone host (127.0.0.1 should just work if you've used &lt;a class="reference external" href="http://wiki.openstack.org/Packstack"&gt;Packstack&lt;/a&gt; as Keystone is probably installed on the same host):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
service_host = ${KEYSTONE-HOSTNAME}
auth_host = ${KEYSTONE-HOSTNAME}
auth_uri = http://${KEYSTONE-HOSTNAME}:35357/v2.0
keystone_ec2_uri = http://${KEYSTONE-HOSTNAME}:5000/v2.0/ec2tokens
&lt;/pre&gt;
&lt;p&gt;In &lt;code&gt;/etc/heat/heat-engine.conf&lt;/code&gt; you've to make sure that all the following variables &lt;strong&gt;do not&lt;/strong&gt; point to 127.0.0.1 even though the services are actually hosted on the same system; these will be passed to the VMs which don't have them available locally:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
heat_metadata_server_url = http://${HEAT-CFN-HOSTNAME}:8000
heat_waitcondition_server_url = http://${HEAT-CFN-HOSTNAME}:8000/v1/waitcondition
heat_watch_server_url = http://${HEAT-CLOUDWATCH-HOSTNAME}:8003
&lt;/pre&gt;
&lt;p&gt;You'll discover that &lt;a class="reference external" href="http://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt; application templates allow for users creation in &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; and these users are, by default, given the role &lt;code&gt;heat_stack_user&lt;/code&gt;. You can configure the role name in &lt;code&gt;heat-engine.conf&lt;/code&gt; or just create a so called role:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# keystone role-create --name heat_stack_user
&lt;/pre&gt;
&lt;p&gt;The configuration should now be complete and the services can be started:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# cd /etc/init.d &amp;amp;&amp;amp; for s in $(ls openstack-heat-*); do chkconfig $s on &amp;amp;&amp;amp; service $s start; done
&lt;/pre&gt;
&lt;p&gt;Make sure by checking the logs that everything was started successfully. Specifically, in case the engine service reports &lt;code&gt;ImportError: cannot import name Random&lt;/code&gt; then you're probably using an old version of &lt;code&gt;pycrypto&lt;/code&gt;. A fix has been merged upstream to workaround the issue. It's &lt;a class="reference external" href="https://review.openstack.org/#/c/26759/"&gt;a trivial change&lt;/a&gt; which you can apply manually to &lt;code&gt;heat/common/crypt.py&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="get-the-demo-files"&gt;
&lt;h2&gt;Get the demo files&lt;/h2&gt;
&lt;p&gt;It is now time to launch our first multi-instance cloud application! There are a number of templates available in the &lt;a class="reference external" href="https://github.com/openstack/heat"&gt;github repo&lt;/a&gt;, download the Wordpress example by doing so:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# wget https://raw.github.com/openstack/heat/master/templates/WordPress_Composed_Instances.template
&lt;/pre&gt;
&lt;p&gt;With &lt;a class="reference external" href="http://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt; you can use the same templates also distributed for &lt;a class="reference external" href="http://aws.amazon.com/cloudformation/"&gt;AWS CloudFormation&lt;/a&gt;. These expect you to have a well known set of flavor types defined but the default types available in &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; don't strictly match the AWS collection. To avoid the need of hack the templates, there is an helpful script which you can use to re-create in &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; the AWS flavors:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# curl https://raw.github.com/openstack/heat/master/tools/nova_create_flavors.sh | bash
&lt;/pre&gt;
&lt;p&gt;Every template also provides you with a list of usable distros and map these into an AMI string, for each arch. You will have to populate Glance with an image matching the AMI string that the template file is expecting to find.&lt;/p&gt;
&lt;p&gt;There is a tool, called &lt;a class="reference external" href="https://github.com/sdake/heat-jeos"&gt;heat-jeos&lt;/a&gt;, which can be used to create the JEOS images and upload them to Glance but there is also a collection of prebuilt images at: &lt;a class="reference external" href="http://fedorapeople.org/groups/heat/prebuilt-jeos-images/"&gt;http://fedorapeople.org/groups/heat/prebuilt-jeos-images/&lt;/a&gt; so I suggest you to just download one of &lt;code&gt;F17-x86_64-cfntools.qcow2&lt;/code&gt; or &lt;code&gt;U10-x86_64-cfntools.qcow2&lt;/code&gt; (which are referred by many if not all the templates available in the Heat's repo). To upload the F17 x86_64 image in Glance:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# glance image-create --name F17-x86_64-cfntools --disk-format qcow2 --container-format bare --is-public True --copy-from http://fedorapeople.org/groups/heat/prebuilt-jeos-images/F17-x86_64-cfntools.qcow2
&lt;/pre&gt;
&lt;p&gt;While that is downloading, create a new keypair or upload you public key in nova to make sure you'll be able to login on the VMs using SSH:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# nova keypair-add --pub_key ~/.ssh/id_rsa.pub userkey
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="launch"&gt;
&lt;h2&gt;Launch!&lt;/h2&gt;
&lt;p&gt;It is time for the real fun now, launch your first composed application with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# heat-cfn create wordpress --template-file=WordPress_Composed_Instances.template --parameters=&amp;quot;DBUsername=wp;DBPassword=wp;KeyName=userkey;LinuxDistribution=F17&amp;quot;
&lt;/pre&gt;
&lt;p&gt;More parameters could have pass, note for instance the LinuxDistribution parameter discussed above. Now the interesting stuff:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# heat-cfn list
# heat-cfn event-list wordpress
&lt;/pre&gt;
&lt;p&gt;After the VMs are launched, the mysql/httpd/wordpress packages are installed, services enabled, database created and so on. This is a process driven by the &lt;code&gt;cfntools&lt;/code&gt; installed in the images and it will take quite some time, despite the &lt;code&gt;event-list&lt;/code&gt; reporting completion for the WordPress install too early (there is signaling, via &lt;code&gt;cfn-signal&lt;/code&gt; only in the MySQL template). You login on any of the instances and check the logs or use &lt;code&gt;ps&lt;/code&gt; to see how things are moving on. After some minutes the setup should be finished:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# heat-cfn describe wordpress
# wget ${WebsiteURL} // from the previous command!
&lt;/pre&gt;
&lt;p&gt;If anything goes wrong, you may want to look at the &lt;code&gt;/var/log/heat/engine.log&lt;/code&gt; file on the &lt;a class="reference external" href="http://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt; host or at the scripts passed as &lt;code&gt;UserData&lt;/code&gt; to the instances, stored in &lt;code&gt;/var/lib/cloud/data/&lt;/code&gt;. Time to hack your very own template and delete the test deployment! :)&lt;/p&gt;
&lt;/div&gt;
</summary><category term="openstack"></category><category term="heat"></category><category term="fedoraplanet"></category><category term="rhel"></category><category term="centos"></category></entry><entry><title>My responsive Svbtle inspired Pelican theme</title><link href="http://www.giuliofidente.com/2013/03/my-responsive-svbtle-inspired-pelican-theme.html" rel="alternate"></link><updated>2013-03-27T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2013-03-27:2013/03/my-responsive-svbtle-inspired-pelican-theme.html</id><summary type="html">&lt;p&gt;I've just pushed on github &lt;a class="reference external" href="http://github.com/giulivo/pelican-svbhack"&gt;my Svbtle inspired theme&lt;/a&gt; for &lt;a class="reference external" href="http://getpelican.com"&gt;Pelican&lt;/a&gt;. I've called it &lt;code&gt;svbhack&lt;/code&gt; and it is the theme that this blog uses.&lt;/p&gt;
&lt;p&gt;As you may notice, this is not (and does not want to be) a close copy of the original &lt;a class="reference external" href="http://www.svbtle.com"&gt;Svbtle&lt;/a&gt; theme; I've taken some ideas from its layout and mixed those with my preferences. Also the CSS is completely rewritten.&lt;/p&gt;
&lt;p&gt;Notable features, it provides support for google analytics and for pre blocks syntax highlight via &lt;code&gt;pygments&lt;/code&gt;. You'll find some examples of this &lt;a class="reference external" href="http://www.giuliofidente.com/2012/06/my-attempts-at-mapreduce-using-mongodb.html"&gt;in my posts&lt;/a&gt; and more informations on how to use it in the project's README file on github.&lt;/p&gt;
&lt;p&gt;Other notable features, you'll get proper links to the category/tag atom feeds in the respective categories/tags listing pages. It's got the archives and the static pages themed too, the css is compiled using &lt;a class="reference external" href="http://lesscss.org"&gt;LESS&lt;/a&gt; and you can easily change the color scheme by hacking a few variables in there (look at the top of &lt;a class="reference external" href="https://github.com/giulivo/pelican-svbhack/blob/master/static/css/style.less"&gt;the style.less file&lt;/a&gt;) and last but not least, it is a &lt;strong&gt;responsive&lt;/strong&gt; layout so it should look nice on your tablet too.&lt;/p&gt;
&lt;p&gt;I decided not to use any existing fluid/grid CSS framework for the simple fact that I couldn't find any which was lightweight enough. Many included UI elements, typography or javascript effects.&lt;/p&gt;
&lt;p&gt;Hope you'll like it. Feedback and patches are very welcomed but you're also free to fork it if you like.&lt;/p&gt;
</summary><category term="pelican"></category><category term="svbtle"></category><category term="svbhack"></category></entry><entry><title>Pretotyping</title><link href="http://www.giuliofidente.com/2013/01/pretotyping.html" rel="alternate"></link><updated>2013-01-03T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2013-01-03:2013/01/pretotyping.html</id><summary type="html">&lt;p&gt;I recently come across the concept of pretotyping. It isn't a misspell, I really meant pretotyping and not prototyping. A formal definition from the book:&lt;/p&gt;
&lt;blockquote&gt;
Testing the initial appeal and actual usage of a potential new product by simulating its core experience with the smallest possible investment of time and money.&lt;/blockquote&gt;
&lt;p&gt;A less formal definition:&lt;/p&gt;
&lt;blockquote&gt;
Make sure as quickly and as cheaply as you can that you are building the right it before you build it right.&lt;/blockquote&gt;
&lt;p&gt;I should have read that before start working on &lt;a class="reference external" href="http://opinoid.com/"&gt;Opinoid&lt;/a&gt;. Still, it's not too late to rework it. I think the book is worth reading by everyone working on new ideas and you can get it for free or for very cheap money from Amazon or at &lt;a class="reference external" href="http://www.pretotyping.org/pretotype-it---the-book"&gt;http://www.pretotyping.org/pretotype-it---the-book&lt;/a&gt;&lt;/p&gt;
</summary><category term="opinoid"></category><category term="pretotyping"></category></entry><entry><title>Open Hybrid PaaS with OpenShift Origin, Katello, and Aeolus</title><link href="http://www.giuliofidente.com/2012/10/open-hybrid-paas-with-openshift-origin-katello-and-aeolus.html" rel="alternate"></link><updated>2012-10-17T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-10-17:2012/10/open-hybrid-paas-with-openshift-origin-katello-and-aeolus.html</id><summary type="html">&lt;p&gt;I found a great post on how to get a working PaaS cloud using only open source technologies. It goes trough &lt;a class="reference external" href="https://openshift.redhat.com/community/open-source"&gt;OpenShift&lt;/a&gt;, &lt;a class="reference external" href="http://www.katello.org/"&gt;Katello&lt;/a&gt;, &lt;a class="reference external" href="http://aeolusproject.org/"&gt;Aeolus&lt;/a&gt; and &lt;a class="reference external" href="http://www.ovirt.org/"&gt;oVirt&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
it's always fun to see what technology can do, and if we don't tinker we'll never drive vision to reality&lt;/blockquote&gt;
&lt;p&gt;See it by yourself: &lt;a class="reference external" href="http://allthingsopen.com/2012/10/16/open-hybrid-paas/"&gt;http://allthingsopen.com/2012/10/16/open-hybrid-paas/&lt;/a&gt;&lt;/p&gt;
</summary><category term="katello"></category><category term="cloud"></category><category term="paas"></category><category term="aeolus"></category><category term="ovirt"></category><category term="openshift"></category></entry><entry><title>1366x768 is not allowed in the EDID block. Here's how to write your XOrg modeline.</title><link href="http://www.giuliofidente.com/2012/10/1366x768-is-not-allowed-in-the-edid-block-heres-how-to-write-your-xorg-modeline.html" rel="alternate"></link><updated>2012-10-09T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-10-09:2012/10/1366x768-is-not-allowed-in-the-edid-block-heres-how-to-write-your-xorg-modeline.html</id><summary type="html">&lt;p&gt;Looks like there are many LCD panels/TVs out there with a native resolution of 1366x768. That is indeed a very close approximation to the expected 16:9 rectangle, except XOrg keeps showing you a resolution of 1360x768 (or 1368x768) instead of the native 1366x768. Why? Because 1366 is not divisible by 8 and that's not valid in an EDID block. &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Extended_display_identification_data#Limitations"&gt;Learn more on wikipedia&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You need a custom &lt;a class="reference external" href="http://en.wikipedia.org/wiki/XFree86_Modeline"&gt;modeline in your xorg.conf&lt;/a&gt; file for that. The NVIDIA drivers also have some &lt;a class="reference external" href="http://us.download.nvidia.com/XFree86/Linux-x86_64/304.43/README/xconfigoptions.html"&gt;ModeValidation&lt;/a&gt; setting which needs some attention. Let's start with the last one, you need to add the following (in the Screen section):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Option &amp;quot;ModeValidation&amp;quot; &amp;quot;AllowNonEdidModes, NoWidthAlignmentCheck&amp;quot;
&lt;/pre&gt;
&lt;p&gt;To make XOrg log files more verbose, you may also want to add the following:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Option &amp;quot;ModeDebug&amp;quot; &amp;quot;True&amp;quot;
&lt;/pre&gt;
&lt;p&gt;And what about the modeline? So &lt;a class="reference external" href="http://howto-pages.org/ModeLines/"&gt;this guy wrote a lot about it&lt;/a&gt; but for our purposes, let's just start with &lt;a class="reference external" href="http://www.xfree86.org/current/xvidtune.1.html"&gt;xvidtune&lt;/a&gt; to check for the current settings:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ xvidtune -show
&amp;quot;1360x768&amp;quot; 84.75 1360 1432 1568 1776 768 771 776 798 -hsync +vsync
&lt;/pre&gt;
&lt;p&gt;After the modeline 'description' (whis is 1360x768), the first number you see represents the pixel clock speed. The remaining eight numbers are two groups of four numbers intended to set the horizontal and vertical resolution. The interesting thing is that you can get your hrefresh and vrefresh value with a simple formula: &lt;code&gt;hrefresh = 84.75/1776&lt;/code&gt; and &lt;code&gt;vrefresh = 84.75/(1776*798)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now, on my LCD manual I had the following valuable informations:&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;1360*768&lt;/dt&gt;
&lt;dd&gt;47.72 59.8 84.75&lt;/dd&gt;
&lt;dt&gt;1366*768&lt;/dt&gt;
&lt;dd&gt;47.56 59.6 84.75&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Those are hrefresh, vrefresh and pixel clock. Let's put those in the modeline adding some more small changes:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;quot;1366x768&amp;quot; 84.75 1366 1438 1574 1782 768 771 776 798 -hsync +vsync
&lt;/pre&gt;
&lt;p&gt;Now here is how the new numbers were found:&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;84.75&lt;/dt&gt;
&lt;dd&gt;is the pixel clock and remains the same as per service manual&lt;/dd&gt;
&lt;dt&gt;1360 became 1366&lt;/dt&gt;
&lt;dd&gt;that's the hresolution we want&lt;/dd&gt;
&lt;dt&gt;1776 became 1782&lt;/dt&gt;
&lt;dd&gt;that is what we need to get the 47.56 hrefresh and 59.6 vrefresh values indicated in the service manual, check yourself with the formula &lt;code&gt;84.75/1782 ~= 47.56&lt;/code&gt; and &lt;code&gt;84.75/(1782\*798) ~= 59.6&lt;/code&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Also, from the initial xvidtune output, the numbers 1432 and 1568 represent some delay, measured in pixels pictured past the viewable area, at the defined pixel clock speed. They are used to set &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Analog_television"&gt;front porch, sync pulse and back porch&lt;/a&gt;; by using 1360 as the number of horizontal pixels you get the following:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(1432-1360)/84.75 = 0.84us black on right side
(1568-1432)/84.75 = 1.60us sync pulse width
(1776-1568)/84.75 = 2.54us black on left side
&lt;/pre&gt;
&lt;p&gt;Now use 1366 as the number of horizontal pixels and keep the delay unchanged:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(1438-1366)/84.75 = 0.84us black on right side
(1574-1438)/84.75 = 1.60us sync pulse width
(1782-1574)/84.75 = 2.54us black on left side
&lt;/pre&gt;
&lt;p&gt;Finally, for this blog post all the values I'm using refer to the LG 37LG3000. Enjoy!&lt;/p&gt;
</summary><category term="1366x768"></category><category term="xorg modeline"></category><category term="linux"></category><category term="fedoraplanet"></category><category term="nvidia"></category></entry><entry><title>UNIX Style, or cat -v Considered Harmful</title><link href="http://www.giuliofidente.com/2012/08/unix-style-or-cat-v-considered-harmful.html" rel="alternate"></link><updated>2012-08-30T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-08-30:2012/08/unix-style-or-cat-v-considered-harmful.html</id><summary type="html">&lt;p&gt;After I got to know &lt;a class="reference external" href="http://harmful.cat-v.org/cat-v/"&gt;cat-v.org&lt;/a&gt;, I read &lt;a class="reference external" href="http://harmful.cat-v.org/cat-v/unix_prog_design.pdf"&gt;Program Design in the UNIX Environment&lt;/a&gt;. A refreshing reading, despite its age.&lt;/p&gt;
&lt;blockquote&gt;
cat isn't for printing files with line numbers, it isn't for compressing multiple blank lines, it's not for looking at non-printing ASCII characters, it's for concatenating files&lt;/blockquote&gt;
</summary><category term="cat"></category><category term="unix"></category></entry><entry><title>Computer Science at Khan Academy</title><link href="http://www.giuliofidente.com/2012/08/computer-science-at-khan-academy.html" rel="alternate"></link><updated>2012-08-20T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-08-20:2012/08/computer-science-at-khan-academy.html</id><summary type="html">&lt;p&gt;Introduction to programming and computer science from &lt;a class="reference external" href="http://www.khanacademy.com"&gt;Khan Academy&lt;/a&gt; at &lt;a class="reference external" href="http://www.khanacademy.org/science/computer-science"&gt;http://www.khanacademy.org/science/computer-science&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The best thing about it is that on Khan you get the tools to coach, not only the chance to learn. Empowers communities.&lt;/p&gt;
</summary><category term="khan academy"></category><category term="computer science"></category></entry><entry><title>My attempts at MapReduce using MongoDB</title><link href="http://www.giuliofidente.com/2012/06/my-attempts-at-mapreduce-using-mongodb.html" rel="alternate"></link><updated>2012-06-14T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-06-14:2012/06/my-attempts-at-mapreduce-using-mongodb.html</id><summary type="html">&lt;p&gt;I was sorting a tree in my (python) webapp instead of having the database to do it for me. This is how I moved it back to the database by using a &lt;a class="reference external" href="http://en.wikipedia.org/wiki/MapReduce"&gt;MapReduce&lt;/a&gt; job. I had a collection structured like the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;...&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;feed_oid&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;4fd268d2ab87b2d8927d7eee&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;title&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;blah blah&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;updated&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1339702524&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;watchers&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;4fd276fc66224c1ee8000006&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Such a collection is called &lt;code&gt;articles&lt;/code&gt; and in there I get a document for every article published by an rss feed. &lt;code&gt;feed_oid&lt;/code&gt; is an identifier I assign to every rss feed that I'm crawling and &lt;code&gt;watchers&lt;/code&gt; contains a list of identifiers assigned to the people voting on such an article.&lt;/p&gt;
&lt;p&gt;I wanted to find out the number of times a particular watcher appeared in the full list of articles and than, group that by the rss feed, so that I could end up with the number of times a person voted on articles published by the same feed.&lt;/p&gt;
&lt;p&gt;The following are my map and reduce functions:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;emit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;feed_oid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;oids&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;vals&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;v&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;vals&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;sum&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nx"&gt;vals&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;v&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The map function is called for every object matching the query filter, so it gets access to 'this'. The reduce function receives an array of values (all set to 1, by my map function) for every feed_oid emitted.&lt;/p&gt;
&lt;p&gt;Here is how I spawn the MapReduce job (querying by the watcher id):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;articles&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;mapReduce&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;query&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;watchers&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;4fd276fc66224c1ee8000006&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="nx"&gt;out&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;mapreduceout&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The results:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;mapreduceout&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;find&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;4fd268d2ab87b2d8927d7eea&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;value&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;4fd268d2ab87b2d8927d7eee&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;value&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Looks like this guy voted 4 times on articles appeared on the feed 4fd268d2ab87b2d8927d7eee and 1 4fd268d2ab87b2d8927d7eea :P&lt;/p&gt;
</summary><category term="mapreduce"></category><category term="fedoraplanet"></category><category term="mongodb"></category></entry><entry><title>Aeolus</title><link href="http://www.giuliofidente.com/2012/06/aeolus.html" rel="alternate"></link><updated>2012-06-08T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-06-08:2012/06/aeolus.html</id><summary type="html">&lt;p&gt;This isn't going to be a real presentation of the &lt;cite&gt;aeolus project&lt;/cite&gt; but I'm currently QAing it and I'd like to to discuss some use cases as there seems to be a lot of confusion around the cloud term these days. Firstly, what is aeolus? It is a collection of tools, you have the full listing at &lt;a class="reference external" href="http://www.aeolusproject.org/projects.html"&gt;http://www.aeolusproject.org/projects.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Basically it allows you to automate the build of your 'template' images and distribute them across different cloud providers, both on premises and hosted. It takes care of stuff like per provider basis image customizations or per arch basis. It manages your &amp;quot;application deployments&amp;quot; rather than instances deployment as it will instantiate more than a single instance and configure them accordingly to provide the cloud user with a, say, wordpress installation distributed across two systems: a web server and a db server.&lt;/p&gt;
&lt;p&gt;Thanks to little things like &lt;a class="reference external" href="http://aeolusproject.org/audrey.html"&gt;audrey&lt;/a&gt; it allows for the image customization not only at build time but also at deployment time and yes, you can pass any data to the scripts running on your guests at deployment time.&lt;/p&gt;
&lt;p&gt;Stay tuned, in the meantime enjoy the demo video: &lt;a class="reference external" href="http://www.redhat.com/resourcelibrary/videos/red-hat-cloudforms-build-cloud-demo-video"&gt;http://www.redhat.com/resourcelibrary/videos/red-hat-cloudforms-build-cloud-demo-video&lt;/a&gt;&lt;/p&gt;
</summary><category term="aeolus"></category><category term="conductor"></category><category term="imagefactory"></category><category term="deltacloud"></category></entry><entry><title>What every programmer should know about memory</title><link href="http://www.giuliofidente.com/2012/05/what-every-programmer-should-know-about-memory.html" rel="alternate"></link><updated>2012-05-02T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-05-02:2012/05/what-every-programmer-should-know-about-memory.html</id><summary type="html">&lt;p&gt;This was a series of posts appeared on LWN, a while ago. A precious document from &lt;a class="reference external" href="http://udrepper.livejournal.com/"&gt;Ulrich Drepper&lt;/a&gt; which have been brought back recently to great attention to me from a post on HN. Thanks Ulrich, LWN and HN:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://lwn.net/Articles/250967/"&gt;Part 1&lt;/a&gt; (Introduction)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://lwn.net/Articles/252125/"&gt;Part 2&lt;/a&gt; (CPU caches)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://lwn.net/Articles/253361/"&gt;Part 3&lt;/a&gt; (Virtual memory)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://lwn.net/Articles/254445/"&gt;Part 4&lt;/a&gt; (NUMA systems)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://lwn.net/Articles/255364/"&gt;Part 5&lt;/a&gt; (What programmers can do - cache optimization)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://lwn.net/Articles/256433/"&gt;Part 6&lt;/a&gt; (What programmers can do - multi-threaded optimizations)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://lwn.net/Articles/257209/"&gt;Part 7&lt;/a&gt; (Memory performance tools)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://lwn.net/Articles/258154/"&gt;Part 8&lt;/a&gt; (Future technologies)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://lwn.net/Articles/258188/"&gt;Part 9&lt;/a&gt; (Appendices and bibliography)&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="linux"></category><category term="memory"></category></entry><entry><title>YUM history (!)</title><link href="http://www.giuliofidente.com/2012/04/yum-history.html" rel="alternate"></link><updated>2012-04-26T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-04-26:2012/04/yum-history.html</id><summary type="html">&lt;p&gt;While browsing the &lt;a class="reference external" href="http://yum.baseurl.org/"&gt;YUM&lt;/a&gt; man page for some details about the query command I happened to find one of my most wanted feature in a package manager! YUM has some &lt;a class="reference external" href="http://docs.fedoraproject.org/en-US/Fedora/16/html/System_Administrators_Guide/sec-Yum-Transaction_History.html"&gt;history&lt;/a&gt; command which allows for investigation of past transactions and even &lt;strong&gt;undo&lt;/strong&gt; or &lt;strong&gt;rollback&lt;/strong&gt; actions. Epic. I frequently find myself going through install/uninstall steps which not only mess around but I tend to forget about the installed and now unneeded deps.&lt;/p&gt;
&lt;p&gt;I'll go through a basic &lt;code&gt;history&lt;/code&gt; usage example but there is a lot more to discover. Consider the following command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# yum install anjuta
...
Installed:
 anjuta.i686 1:3.2.0-1.fc16

Dependency Installed:
 apr.i686 0:1.4.6-1.fc16
 apr-util.i686 0:1.3.12-1.fc16
 autogen.i686 0:5.9.4-8.fc15
 autogen-libopts.i686 0:5.9.4-8.fc15
 devhelp.i686 1:3.2.0-1.fc16
 glade3-libgladeui.i686 1:3.10.0-6.fc16
 guile.i686 5:1.8.8-3.fc16
 libgda.i686 1:4.2.8-2.fc16
 libgda-sqlite.i686 1:4.2.8-2.fc16
 libgdl.i686 1:3.2.0-1.fc16
 sqlite-devel.i686 0:3.7.7.1-1.fc16
 subversion-libs.i686 0:1.6.17-5.fc16
 vala.i686 0:0.14.2-3.fc16
&lt;/pre&gt;
&lt;p&gt;Many dependencies have been installed and you surely won't remember all of them when later removing anjuta. You could go through some cleaning session using &lt;code&gt;package-cleanup&lt;/code&gt;, from
&lt;a class="reference external" href="http://yum.baseurl.org/wiki/YumUtils"&gt;yum-utils&lt;/a&gt; but that isn't really intended to revert back your system status, it will just help you remove unneeded packages. Here's instead what &lt;code&gt;history&lt;/code&gt; can do for you:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# yum history list anjuta
Loaded plugins: downloadonly, langpacks, presto, refresh-packagekit
ID   | Command line       | Date and time    | Action(s)  | Altered
-------------------------------------------------------------------
 172 | install anjuta     | 2012-04-26 09:02 | Install    |   14

# yum history info 172
Loaded plugins: downloadonly, langpacks, presto, refresh-packagekit
Transaction ID : 172
Begin time     : Thu Apr 26 09:02:57 2012
Begin rpmdb    : 1225:459cfe1ee50fe38d585386f265e6647ab8d4b5a9
End time       :            09:03:19 2012 (22 seconds)
End rpmdb      : 1239:9784f29b6dff78d982e401bfa5e4cbd9620c47ed
User           : Giulio Fidente
Return-Code    : Success
Command Line   : install anjuta
Transaction performed with:
    Installed     rpm-4.9.1.3-1.fc16.i686               &amp;#64;updates
    Installed     yum-3.4.3-23.fc16.noarch              &amp;#64;updates
    Installed     yum-metadata-parser-1.1.4-5.fc16.i686 &amp;#64;koji-overrides
Packages Altered:
    Install     anjuta-1:3.2.0-1.fc16.i686             &amp;#64;fedora
    Dep-Install apr-1.4.6-1.fc16.i686                  &amp;#64;updates
    Dep-Install apr-util-1.3.12-1.fc16.i686            &amp;#64;fedora
    Dep-Install autogen-5.9.4-8.fc15.i686              &amp;#64;fedora
    Dep-Install autogen-libopts-5.9.4-8.fc15.i686      &amp;#64;fedora
    Dep-Install devhelp-1:3.2.0-1.fc16.i686            &amp;#64;fedora
    Dep-Install glade3-libgladeui-1:3.10.0-6.fc16.i686 &amp;#64;updates
    Dep-Install guile-5:1.8.8-3.fc16.i686              &amp;#64;fedora
    Dep-Install libgda-1:4.2.8-2.fc16.i686             &amp;#64;updates
    Dep-Install libgda-sqlite-1:4.2.8-2.fc16.i686      &amp;#64;updates
    Dep-Install libgdl-1:3.2.0-1.fc16.i686             &amp;#64;fedora
    Dep-Install sqlite-devel-3.7.7.1-1.fc16.i686       &amp;#64;fedora
    Dep-Install subversion-libs-1.6.17-5.fc16.i686     &amp;#64;fedora
    Dep-Install vala-0.14.2-3.fc16.i686                &amp;#64;updates

# yum history undo 172
...
Removed:
 anjuta.i686 1:3.2.0-1.fc16
 apr.i686 0:1.4.6-1.fc16
 apr-util.i686 0:1.3.12-1.fc16
 autogen.i686 0:5.9.4-8.fc15
 autogen-libopts.i686 0:5.9.4-8.fc15
 devhelp.i686 1:3.2.0-1.fc16
 glade3-libgladeui.i686 1:3.10.0-6.f16
 guile.i686 5:1.8.8-3.fc16
 libgda.i686 1:4.2.8-2.fc16
 libgda-sqlite.i686 1:4.2.8-2.fc16
 libgdl.i686 1:3.2.0-1.fc16
 sqlite-devel.i686 0:3.7.7.1-1.fc16
 subversion-libs.i686 0:1.6.17-5.fc16
 vala.i686 0:0.14.2-3.fc16
&lt;/pre&gt;
&lt;p&gt;Great isn't it? And there is a lot more! The &lt;code&gt;rollback&lt;/code&gt; command will revert back the status of the &lt;strong&gt;whole&lt;/strong&gt; software packages installed at the time of the transaction ID.&lt;/p&gt;
</summary><category term="fedora"></category><category term="fedoraplanet"></category><category term="yum"></category></entry><entry><title>Jenkins on OpenShift</title><link href="http://www.giuliofidente.com/2012/04/jenkins-on-openshift.html" rel="alternate"></link><updated>2012-04-19T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-04-19:2012/04/jenkins-on-openshift.html</id><summary type="html">&lt;p&gt;How about &lt;a class="reference external" href="http://jenkins-ci.org/"&gt;Jenkins&lt;/a&gt; on &lt;a class="reference external" href="http://openshift.redhat.com/"&gt;OpenShift&lt;/a&gt;? Let's give this a try. Keep in mind that by default you've got only 3 gears on OpenShift and we'll need to use all of them for this tutorial:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;1 will be used by the live app&lt;/li&gt;
&lt;li&gt;1 will be used by the jenkins deployment&lt;/li&gt;
&lt;li&gt;1 will be used by the jenkins builds&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, create your jenkins deployment:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ rhc app create -a jenkins -t jenkins-1.4
&lt;/pre&gt;
&lt;p&gt;Then create your app (I'm using the DIY cartridge, but this will work with all other types too):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ rhc app create -a hellojenkins -t diy-0.1
&lt;/pre&gt;
&lt;p&gt;And add to it the jenkins-client cartridge:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ rhc app cartridge add -a hello -c jenkins-client-1.4
&lt;/pre&gt;
&lt;p&gt;Now, change your app build file into something useful and push it:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ cd hellojenkins
$ echo env &amp;gt;&amp;gt; .openshift/action_hooks/build
$ git commit -a
$ git push
&lt;/pre&gt;
&lt;p&gt;Hurry up checking your build on jenkins: &lt;a class="reference external" href="https://jenkins-$USERNAME.rhcloud.com/job/hellojenkins-build/"&gt;https://jenkins-$USERNAME.rhcloud.com/job/hellojenkins-build/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wow. That was easy! Now imagine what you could do in your pre_build/build/post_deploy scripts with jenkins.&lt;/p&gt;
</summary><category term="jenkins"></category><category term="openshift"></category></entry><entry><title>TornadoWeb on OpenShift (updates)</title><link href="http://www.giuliofidente.com/2012/04/tornadoweb-on-openshift-updates.html" rel="alternate"></link><updated>2012-04-02T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-04-02:2012/04/tornadoweb-on-openshift-updates.html</id><summary type="html">&lt;p&gt;&lt;a class="reference external" href="http://openshift.redhat.com"&gt;OpenShift&lt;/a&gt; recently introduced a new &lt;a class="reference external" href="https://www.redhat.com/openshift/community/blogs/new-openshift-release-march-22-2012-nodejs-diy-cartridge-new-website-and-more"&gt;DIY cartridge&lt;/a&gt; which allows for execution of any HTTP server.  Some nice features of &lt;a class="reference external" href="http://www.tornadoweb.org"&gt;TornadoWeb&lt;/a&gt; (like the auth modules) are not available when running as WSGI, as that doesn't permit ASYNC requests so I decided to &lt;a class="reference external" href="https://github.com/giulivo/openshift-hellotornado"&gt;update the past HOWTO&lt;/a&gt; documenting how to deploy it using the new DIY cartridge. Enjoy!&lt;/p&gt;
</summary><category term="tornado"></category><category term="openshift"></category></entry><entry><title>Migrate NIS to FreeIPA</title><link href="http://www.giuliofidente.com/2012/03/migrate-nis-to-freeipa.html" rel="alternate"></link><updated>2012-03-04T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-03-04:2012/03/migrate-nis-to-freeipa.html</id><summary type="html">&lt;p&gt;I've prepared a quick HOWTO on how to migrate a legacy NIS environment to FreeIPA (ldap/kerberos). I hope it will be useful to some: &lt;a class="reference external" href="http://freeipa.org/page/NIS_accounts_migration_preserving_Passwords"&gt;http://freeipa.org/page/NIS_accounts_migration_preserving_Passwords&lt;/a&gt;&lt;/p&gt;
</summary><category term="freeipa"></category><category term="kerberos"></category><category term="ldap"></category><category term="nis"></category><category term="ipa"></category></entry><entry><title>A quickstart guide to the command line OpenShift client</title><link href="http://www.giuliofidente.com/2012/02/a-quickstart-guide-to-the-command-line-openshift-client.html" rel="alternate"></link><updated>2012-02-24T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-02-24:2012/02/a-quickstart-guide-to-the-command-line-openshift-client.html</id><summary type="html">&lt;p&gt;I've published a little guide to the rhc command line tool, that is the command line tool (ruby gem) needed to deploy your apps on &lt;a class="reference external" href="http://openshift.redhat.com"&gt;OpenShift&lt;/a&gt;. You can find it here: &lt;a class="reference external" href="https://github.com/giulivo/openshift-rhc-quickstart"&gt;https://github.com/giulivo/openshift-rhc-quickstart&lt;/a&gt;&lt;/p&gt;
</summary><category term="red hat"></category><category term="openshift"></category></entry><entry><title>Flask, jQuery Mobile and MongoDB on OpenShift</title><link href="http://www.giuliofidente.com/2012/02/flask-jquery-mobile-and-mongodb-on-openshift.html" rel="alternate"></link><updated>2012-02-23T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-02-23:2012/02/flask-jquery-mobile-and-mongodb-on-openshift.html</id><summary type="html">&lt;p&gt;I've published a demo webapp for mobiles written using &lt;a class="reference external" href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; and &lt;a class="reference external" href="http://jquerymobile.com/"&gt;jQuery Mobile&lt;/a&gt;. The backend storage is &lt;a class="reference external" href="http://www.mongodb.org/"&gt;MongoDB&lt;/a&gt;. The app allows you to check and edit a shopping lists from your mobile phone so that if your fellow file the list from home, you'll have it at your finger tips later, when at the mall!&lt;/p&gt;
&lt;p&gt;This has been deployed on &lt;a class="reference external" href="http://openshift.redhat.com/"&gt;OpenShift&lt;/a&gt; which offers MongoDB instances for free, as well as support for any Python WSGI app. Flask is installed using virtualenv, see &lt;a class="reference external" href="https://github.com/giulivo/openshift-myshoppinglist"&gt;https://github.com/giulivo/openshift-myshoppinglist&lt;/a&gt; for it and enjoy!&lt;/p&gt;
</summary><category term="flask"></category><category term="mongodb"></category><category term="openshift"></category><category term="jquery mobile"></category></entry><entry><title>TornadoWeb on OpenShift</title><link href="http://www.giuliofidente.com/2012/02/tornadoweb-on-openshift.html" rel="alternate"></link><updated>2012-02-17T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-02-17:2012/02/tornadoweb-on-openshift.html</id><summary type="html">&lt;p&gt;I've published a some notes on how to deploy a &lt;a class="reference external" href="http://www.tornadoweb.org"&gt;TornadoWeb&lt;/a&gt; based app on &lt;a class="reference external" href="http://openshift.redhat.com"&gt;OpenShift&lt;/a&gt;, here they are including the demo app: &lt;a class="reference external" href="https://github.com/giulivo/openshift-hellotornado"&gt;https://github.com/giulivo/openshift-hellotornado&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hop you'll fork it and have much fun, as I did.&lt;/p&gt;
</summary><category term="tornado"></category><category term="openshift"></category></entry><entry><title>DNS Classless IN-ADDR.ARPA delegation</title><link href="http://www.giuliofidente.com/2012/01/dns-classless-in-addrarpa-delegation.html" rel="alternate"></link><updated>2012-01-19T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2012-01-19:2012/01/dns-classless-in-addrarpa-delegation.html</id><summary type="html">&lt;p&gt;The following is mostly taken from &lt;a class="reference external" href="http://tools.ietf.org/html/rfc2317"&gt;http://tools.ietf.org/html/rfc2317&lt;/a&gt; but it is so good I wanted to share it here. Basically this allows for DNS delegation of the reverse zone for address spaces covering fewer than 256 addresses. Let us assume we have assigned the address spaces to three different parties as follows:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
192.0.2.0/25 to organization A
192.0.2.128/26 to organization B
192.0.2.192/26 to organization C
&lt;/pre&gt;
&lt;p&gt;In the classical approach, this would lead to a single zone like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ORIGIN 2.0.192.in-addr.arpa.
;
1               PTR     host1.A.domain.
2               PTR     host2.A.domain.
3               PTR     host3.A.domain.
;
129             PTR     host1.B.domain.
130             PTR     host2.B.domain.
131             PTR     host3.B.domain.
;
193             PTR     host1.C.domain.
194             PTR     host2.C.domain.
195             PTR     host3.C.domain.
&lt;/pre&gt;
&lt;p&gt;The administration of this zone is problematic. Authority for this zone can only be delegated once, and this usually translates into &amp;quot;this zone can only be administered by one organization.&amp;quot; The other organizations with address space that corresponds to entries in this zone would thus have to depend on another organization for their address to name translation. With the proposed method, this potential problem can be avoided. Since a single zone can only be delegated once, we need more points to do delegation on to solve the problem above. These extra points of delegation can be introduced by extending the IN-ADDR.ARPA tree downwards, e.g. by using the first address or the first address and the network mask length (as shown below) in the corresponding address space to form the the first component in the name for the zones. The following four zone files show how the problem in the motivation section could be solved using this method.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ORIGIN 2.0.192.in-addr.arpa.
&amp;#64;       IN      SOA     my-ns.my.domain. hostmaster.my.domain. (...)
;...
;  &amp;lt;&amp;lt;0-127&amp;gt;&amp;gt; /25
0/25            NS      ns.A.domain.
0/25            NS      some.other.name.server.
;
1               CNAME   1.0/25.2.0.192.in-addr.arpa.
2               CNAME   2.0/25.2.0.192.in-addr.arpa.
3               CNAME   3.0/25.2.0.192.in-addr.arpa.
;
;  &amp;lt;&amp;lt;128-191&amp;gt;&amp;gt; /26
128/26          NS      ns.B.domain.
128/26          NS      some.other.name.server.too.
;
129             CNAME   129.128/26.2.0.192.in-addr.arpa.
130             CNAME   130.128/26.2.0.192.in-addr.arpa.
131             CNAME   131.128/26.2.0.192.in-addr.arpa.
;
;  &amp;lt;&amp;lt;192-255&amp;gt;&amp;gt; /26
192/26          NS      ns.C.domain.
192/26          NS      some.other.third.name.server.
;
193             CNAME   193.192/26.2.0.192.in-addr.arpa.
194             CNAME   194.192/26.2.0.192.in-addr.arpa.
195             CNAME   195.192/26.2.0.192.in-addr.arpa.

$ORIGIN 0/25.2.0.192.in-addr.arpa.
&amp;#64;       IN      SOA     ns.A.domain. hostmaster.A.domain. (...)
&amp;#64;               NS      ns.A.domain.
&amp;#64;               NS      some.other.name.server.
;
1               PTR     host1.A.domain.
2               PTR     host2.A.domain.
3               PTR     host3.A.domain.
$ORIGIN 128/26.2.0.192.in-addr.arpa.
&amp;#64;       IN      SOA     ns.B.domain. hostmaster.B.domain. (...)
&amp;#64;               NS      ns.B.domain.
&amp;#64;               NS      some.other.name.server.too.
;
129             PTR     host1.B.domain.
130             PTR     host2.B.domain.
131             PTR     host3.B.domain.
$ORIGIN 192/26.2.0.192.in-addr.arpa.
&amp;#64;       IN      SOA     ns.C.domain. hostmaster.C.domain. (...)
&amp;#64;               NS      ns.C.domain.
&amp;#64;               NS      some.other.third.name.server.
;
193             PTR     host1.C.domain.
194             PTR     host2.C.domain.
195             PTR     host3.C.domain.
&lt;/pre&gt;
</summary><category term="dns"></category><category term="classless reverse zone delegation"></category></entry><entry><title>Instant CSS, JS, HTML or DOM documentation</title><link href="http://www.giuliofidente.com/2011/12/instant-css-js-html-or-dom-documentation.html" rel="alternate"></link><updated>2011-12-07T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2011-12-07:2011/12/instant-css-js-html-or-dom-documentation.html</id><summary type="html">&lt;p&gt;Worth sharing: &lt;a class="reference external" href="http://dochub.io/"&gt;http://dochub.io/&lt;/a&gt;&lt;/p&gt;
</summary><category term="hacker news"></category><category term="documentation"></category></entry><entry><title>Red Hat Enterprise Virtualization is oVirt</title><link href="http://www.giuliofidente.com/2011/09/red-hat-enterprise-virtualization-is-ovirt.html" rel="alternate"></link><updated>2011-09-23T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2011-09-23:2011/09/red-hat-enterprise-virtualization-is-ovirt.html</id><summary type="html">&lt;p&gt;Red Hat Enterprise Virtualization &lt;a class="reference external" href="http://www.ovirt.org/news-and-events/workshop/"&gt;going open source&lt;/a&gt; as oVirt [relaunched]. There will be a workshop in November, open to all who want to use, get involved or learn about the comprehensive open virtualization management platform. The sessions will cover the technical projects details, governance, getting involved, usage and much more.&lt;/p&gt;
&lt;p&gt;Full GIT repos (source), site, forums will be launched at the event!&lt;/p&gt;
</summary><category term="rhev"></category><category term="ovirt"></category><category term="red hat enterprise virtualization"></category><category term="rhev"></category></entry><entry><title>The IP header, using Lego bricks</title><link href="http://www.giuliofidente.com/2010/07/the-ip-header-using-lego-bricks.html" rel="alternate"></link><updated>2010-07-22T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2010-07-22:2010/07/the-ip-header-using-lego-bricks.html</id><summary type="html">&lt;p&gt;This came from &lt;a class="reference external" href="http://www.reddit.com"&gt;reddit&lt;/a&gt;, can you guess what this is? (possibly without scrolling immediately down the page to read the response)&lt;/p&gt;
&lt;img alt="|filename|/images/legoip.jpg" src="http://www.giuliofidente.com/static/images/legoip.jpg" /&gt;
&lt;p&gt;Just &lt;a class="reference external" href="http://www.lego.com"&gt;LEGO&lt;/a&gt; bricks you say? This is the &lt;a class="reference external" href="http://en.wikipedia.org/wiki/IPv4_header#Header"&gt;IP header&lt;/a&gt; made up with such bricks! How can you &lt;strong&gt;not&lt;/strong&gt; like it?&lt;/p&gt;
</summary><category term="lego"></category><category term="tcp"></category><category term="ip"></category><category term="tcp/ip"></category></entry><entry><title>Audio extraction from DVDs</title><link href="http://www.giuliofidente.com/2009/08/audio-extraction-from-dvds.html" rel="alternate"></link><updated>2009-08-25T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2009-08-25:2009/08/audio-extraction-from-dvds.html</id><summary type="html">&lt;p&gt;I recently bought some dvds and they don't contain films but concerts so after the few plays I decided to extract the audio tracks, possibly keeping the highest audio quality permitted, to convert them later into mp3, ogg or flac as needed. I want to discuss the process.&lt;/p&gt;
&lt;p&gt;The first tool I found useful was &lt;a class="reference external" href="http://untrepid.com/acidrip/lsdvd.html"&gt;lsdvd&lt;/a&gt;, it tells you the number and length of titles, chapters and angles available on the dvd, which is important stuff to go further. Then I picked &lt;a class="reference external" href="http://tcforge.berlios.de/"&gt;transcode&lt;/a&gt; to extract the actual audio data, because it can write audio on disk in raw PCM format (lossless) and because it's very flexible. Here is how to extract the audio from a single chapter (which you can put in a for loop) using transcode:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ transcode -i /dev/dvd -x null,dvd -T 1,1,1 -a 0 -y null,tcaud -N 0x1 -m track1.pcm
&lt;/pre&gt;
&lt;p&gt;Where arguments for -T are title, chapter and angle of the track you want to extract and argument for -N is the audio output format (0x1 is raw PCM). After that, you'll have to convert your PCM files into a more practical format ... mp3 for example, here is how I did it:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ lame -r -s 48 --preset extreme track1.pcm
&lt;/pre&gt;
&lt;p&gt;You can use any other lame option, just keep in mind that -r is important, it tells lame that your input file is in raw format (as in fact, we wanted it to be). Giving a look at the lame man page you'll notice it also says that -r expects you to define manually the sampling rate, mode and bitwidth of the input data; you can safely omit mode (which will be joint stereo by default) and the bitwidth (which will be 16) but you'll need to specify the sampling rate. 48KHz is most likely what you'll get on a regulard dvd, lame would otherwise assume it's 44.1KHz.&lt;/p&gt;
&lt;p&gt;Something similar could be used to encode your raw files into the ogg format (oggenc is part of the vorbis-tools package); in my case 8 as quality is chosen to get the output files comparable in size with mp3:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ oggenc -r -R 48000 -q 8 track1.pcm -o track1.pcm.ogg
&lt;/pre&gt;
&lt;p&gt;On a side node, if you want to get your mp3 files all rolled in just one step, you may want to try the transcode's encoding:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ transcode -i /dev/dvd -x dvd -T 1,1,1 -a 0 -y null,tcaud --lame_preset extreme -m track1.mp3
&lt;/pre&gt;
&lt;p&gt;Enjoy :)&lt;/p&gt;
</summary><category term="transcoding"></category><category term="dvd audio extraction"></category></entry><entry><title>OS X Network Install using Linux (updates)</title><link href="http://www.giuliofidente.com/2009/01/os-x-network-install-using-linux-updates.html" rel="alternate"></link><updated>2009-01-06T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2009-01-06:2009/01/os-x-network-install-using-linux-updates.html</id><summary type="html">&lt;p&gt;Do you still remember &lt;a class="reference external" href="http://www.giuliofidente.com/2006/11/os-x-network-install-using-linux.html"&gt;this&lt;/a&gt;? It was a good post about the OS X install via the network using a GNU/Linux install server. I went back to read and use it after a few days to install the version 10.5 (leopard) of OS X and it worked well but there's a couple of things missing in that post which I'd like to share here.&lt;/p&gt;
&lt;p&gt;The problems were mainly in mounting the leopard disc. If you try to do that on a GNU/Linux system you should only see some files about bootcamp, it is indeed a double format dvd which includes two sections, one is iso9660 formatted and another is hfs+ formatted. To find the files I mentioned, you'll have to mount the hfs+ formatted section ... which is hidden but you can find it using this very helpful link: &lt;a class="reference external" href="http://www.64lines.com/mounting-hfs-plus"&gt;Mounting HFS+ Hybrid Disks on Linux&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also, because of the additional steps, when you're at this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
dd if=/dev/hdc of=/tftpboot/macosx.img
&lt;/pre&gt;
&lt;p&gt;you'll have to replace /dev/hdc with the /dev/loop0 device created by the instructions linked before.&lt;/p&gt;
</summary><category term="osx network install"></category><category term="linux network install"></category><category term="leopard network install"></category><category term="fedoraplanet"></category></entry><entry><title>A small portion of extra time</title><link href="http://www.giuliofidente.com/2008/12/a-small-portion-of-extra-time.html" rel="alternate"></link><updated>2008-12-31T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2008-12-31:2008/12/a-small-portion-of-extra-time.html</id><summary type="html">&lt;p&gt;For three years it was possible to do without it. But now it's become necessary again. This coming New Year's Eve, the radio controlled clocks will, after 0:59:59, instead of jumping to 1 o'clock at the next tick of the second, pause shortly in order to insert a small portion of extra time: a leap second.&lt;/p&gt;
&lt;p&gt;The International Earth Rotation Service (IERS) in Paris has prescribed this addition to coordinated universal time (UTC), as our Earth is again too much out of sync. The Earth lags behind atomic clock time, whose ticking seconds do not pay attention to any earthly fluctuation. This leap second will be dispensed to the German clocks by the Physikalisch-Technische Bundesanstalt (PTB) in Braunschweig.&lt;/p&gt;
&lt;p&gt;Find all answers to your questions about time at &lt;a class="reference external" href="http://www.ptb.de/en/wegweiser/infoszurzeit/index.html"&gt;http://www.ptb.de/en/wegweiser/infoszurzeit/index.html&lt;/a&gt;&lt;/p&gt;
</summary><category term="new year's eve"></category><category term="extra time"></category></entry><entry><title>RHEL5, GFS2 and DRBD8</title><link href="http://www.giuliofidente.com/2007/04/rhel5-gfs2-and-drbd8.html" rel="alternate"></link><updated>2007-04-03T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2007-04-03:2007/04/rhel5-gfs2-and-drbd8.html</id><summary type="html">&lt;p&gt;I've finally built my first &lt;a class="reference external" href="http://sourceware.org/cluster/"&gt;cluster&lt;/a&gt; on &lt;a class="reference external" href="http://www.redhat.com/rhel/"&gt;rhel5&lt;/a&gt; using &lt;a class="reference external" href="http://sourceware.org/cluster/"&gt;gfs2&lt;/a&gt; and &lt;a class="reference external" href="http://www.drbd.org/"&gt;drbd8&lt;/a&gt; :-D&lt;/p&gt;
&lt;p&gt;drbd makes a network raid1 between two physical distinguished block devices (eg. internal disks of two servers) and from the release 8.0 it supports the active/active configuration.&lt;/p&gt;
&lt;p&gt;gfs2 permits to the two server machines a concurrent mount of the network replicated drbd device.&lt;/p&gt;
&lt;p&gt;rhel5 is the OS I've installed on the two machines.&lt;/p&gt;
&lt;p&gt;Practically with this stuff the servers share the same &amp;quot;storage&amp;quot;. Here is a sample config file for drbd:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="err"&gt;common&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="err"&gt;syncer&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt; &lt;span class="err"&gt;rate&lt;/span&gt; &lt;span class="err"&gt;100M;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="err"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;resource&lt;/span&gt; &lt;span class="err"&gt;r&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="err"&gt;protocol&lt;/span&gt; &lt;span class="err"&gt;C;&lt;/span&gt;
  &lt;span class="err"&gt;disk&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt; &lt;span class="err"&gt;on-io-error&lt;/span&gt; &lt;span class="err"&gt;pass_on;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="err"&gt;net&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="err"&gt;allow-two-primaries;&lt;/span&gt;
    &lt;span class="err"&gt;after-sb-0pri&lt;/span&gt; &lt;span class="err"&gt;discard-least-changes;&lt;/span&gt;
    &lt;span class="err"&gt;after-sb-1pri&lt;/span&gt; &lt;span class="err"&gt;discard-secondary;&lt;/span&gt;
    &lt;span class="err"&gt;after-sb-2pri&lt;/span&gt; &lt;span class="err"&gt;violently-as0p;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="err"&gt;on&lt;/span&gt; &lt;span class="err"&gt;bsvm&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="err"&gt;.babel.int&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="err"&gt;address&lt;/span&gt; &lt;span class="err"&gt;192.168.1.1:7790;&lt;/span&gt;
    &lt;span class="err"&gt;disk&lt;/span&gt; &lt;span class="err"&gt;/dev/mapper/ddf1_ld0p5;&lt;/span&gt;
    &lt;span class="err"&gt;device&lt;/span&gt; &lt;span class="err"&gt;/dev/drbd0;&lt;/span&gt;
    &lt;span class="err"&gt;meta-disk&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;internal&amp;quot;&lt;/span&gt;&lt;span class="err"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="err"&gt;on&lt;/span&gt; &lt;span class="err"&gt;bsvm&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="err"&gt;.babel.int&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="err"&gt;address&lt;/span&gt; &lt;span class="err"&gt;192.168.1.2:7790;&lt;/span&gt;
    &lt;span class="err"&gt;disk&lt;/span&gt; &lt;span class="err"&gt;/dev/mapper/ddf1_ld0p5;&lt;/span&gt;
    &lt;span class="err"&gt;device&lt;/span&gt; &lt;span class="err"&gt;/dev/drbd0;&lt;/span&gt;
    &lt;span class="err"&gt;meta-disk&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;internal&amp;quot;&lt;/span&gt;&lt;span class="err"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Want to give it a try? Configure your cluster.xml file, start the drbd and cman services, create the filesystem on the drbd device and ... have fun!!&lt;/p&gt;
</summary><category term="gfs"></category><category term="rhel"></category><category term="drbd"></category></entry><entry><title>Fluendo on PPC</title><link href="http://www.giuliofidente.com/2006/11/fluendo-on-ppc.html" rel="alternate"></link><updated>2006-11-04T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2006-11-04:2006/11/fluendo-on-ppc.html</id><summary type="html">&lt;p&gt;Unfortunately my GNU/Linux box is a PowerPC and I had the privilege of finding all sort of strange Fluendo bugs... but apart from bugs, the gstreamer0.10-fluendo-mp3 plugin consumes much more CPU (about 22% against 7%) than the standard mad plugin for gstreamer (found in gstreamer0.10-plugins-ugly collection) and fluendo-mp3 is licensed under the MIT license while the mad library is instead GPL. Last but not least, I've no data to show that but it seems to me that also the audio quality is better with mad!&lt;/p&gt;
&lt;p&gt;MAD better than FLUENDO on PPC!&lt;/p&gt;
</summary><category term="fluendo"></category><category term="ppc"></category></entry><entry><title>OS X Network Install using Linux</title><link href="http://www.giuliofidente.com/2006/11/os-x-network-install-using-linux.html" rel="alternate"></link><updated>2006-11-01T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:www.giuliofidente.com,2006-11-01:2006/11/os-x-network-install-using-linux.html</id><summary type="html">&lt;p&gt;The title says it all. We're going to install an OS X client via network using a GNU/Linux box as DHCP/TFTP/NFS server.&lt;/p&gt;
&lt;p&gt;First you'll want to setup your DHCP, TFTP and NFS server.&lt;/p&gt;
&lt;p&gt;The default location for the TFTP server root on my system was &lt;code&gt;/tftpboot&lt;/code&gt;. It may be different on other distro so change at will. This directory is where we're going to put all the important files. Three files come from the OS X disc (although you'll have to rename two of them) and the fourth is a simple image of the OS X disc itself.&lt;/p&gt;
&lt;p&gt;Mount the Mac OS X disc and copy and rename the following files into your TFTP server root&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cp /cdrom/System/Library/CoreServices/BootX /tftpboot/BootX
cp /cdrom/mach\_kernel /tftpboot/mach.macosx
cp /cdrom/System/Library/Extensions.mkext /tftpboot/mach.macosx.mkext
&lt;/pre&gt;
&lt;p&gt;Unmount and make an image of the install disc in the TFTP server root&lt;/p&gt;
&lt;pre class="literal-block"&gt;
dd if=/dev/hdc of=/tftpboot/macosx.img
&lt;/pre&gt;
&lt;p&gt;On your NFS server, you'll want to modify &lt;code&gt;/etc/exports&lt;/code&gt; to include something like the following&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/tftpboot/ mac-ip-address(ro,insecure)
&lt;/pre&gt;
&lt;p&gt;where mac-ip-address is the mac address assigned to your mac manually (see step 7) or by the DHCP server.&lt;/p&gt;
&lt;p&gt;At this point you'll want to start the TFTP server and NFS services.&lt;/p&gt;
&lt;p&gt;Boot into the open firmware (by holding command+option+O+F) and issue the following commands&lt;/p&gt;
&lt;pre class="literal-block"&gt;
setenv boot-device enet:ip-address-of-linux-server,BootX
setenv boot-args rp=nfs:ip-address-of-linux-server:/tftpboot/:macosx.img
boot
&lt;/pre&gt;
&lt;p&gt;where ip-address-of-linux-server is... self-explanatory.&lt;/p&gt;
&lt;p&gt;The well familiar Mac boot sequence should start except now you have a little spinning world as logo while it tries to make a connection to the Linux server. You'll probably want to hold command+V while booting the Mac to see what's actually happening and to ensure the whole process is going smoothly.&lt;/p&gt;
&lt;p&gt;I hope it helped!&lt;/p&gt;
</summary><category term="osx network install"></category><category term="linux network install"></category><category term="leopard network install"></category><category term="fedoraplanet"></category></entry></feed>