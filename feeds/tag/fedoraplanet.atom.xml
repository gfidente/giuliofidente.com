<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Giulio Fidente (aka Giulivo Navigante)</title><link href="http://giuliofidente.com/" rel="alternate"></link><link href="http://giuliofidente.com/feeds/tag/fedoraplanet.atom.xml" rel="self"></link><id>http://giuliofidente.com/</id><updated>2013-06-16T16:37:00+02:00</updated><entry><title>OpenStack Cinder - Configure multiple backends</title><link href="http://giuliofidente.com/2013/06/openstack-cinder-configure-multiple-backends.html" rel="alternate"></link><updated>2013-06-16T16:37:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:giuliofidente.com,2013-06-16:2013/06/openstack-cinder-configure-multiple-backends.html</id><summary type="html">&lt;p&gt;Following &lt;a class="reference external" href="http://giuliofidente.com/2013/04/openstack-cinder-add-more-volume-nodes.html"&gt;my first post of the series&lt;/a&gt; discussing how to scale &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Cinder"&gt;Cinder&lt;/a&gt; to multiple nodes, with this I want to approach the configuration and usage of the multibackend feature landed in &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Cinder"&gt;Cinder&lt;/a&gt; with the Grizzly release.&lt;/p&gt;
&lt;p&gt;This feature allows you to configure a single volume node for use with more than a single backend driver. You can find all about the few configuration bits needed also in the &lt;a class="reference external" href="http://docs.openstack.org/trunk/openstack-block-storage/admin/content/multi_backend.html"&gt;OpenStack block storage documentation&lt;/a&gt;. That makes this post somehow redundant but I wanted to keep up with the series and the topic is well worth to be kept also here.&lt;/p&gt;
&lt;p&gt;As usual, some assumptions before we start:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;you're familiar with the general &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; architecture&lt;/li&gt;
&lt;li&gt;you have already some &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Cinder"&gt;Cinder&lt;/a&gt; volume node configured and working as expected&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Assuming we want our node, configured with some LVM based and an additional NFS based backend, this is what we would need to add into &lt;code&gt;cinder.conf&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
enabled_backends=lvm1,nfs1
[lvm1]
volume_driver=cinder.volume.drivers.lvm.LVMISCSIDriver
volume_backend_name=LVM_iSCSI
[nfs1]
nfs_shares_config=${PATH_TO_YOUR_SHARES_FILE}
volume_driver=cinder.volume.drivers.nfs.NfsDriver
volume_backend_name=NFS
&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;enabled_backends&lt;/code&gt; value defines some names (separated by a comma) for the config groups. These do not have to match the driver name nor the backend name.&lt;/p&gt;
&lt;p&gt;When the configuration is complete, to use a particular backend when allocating new volumes, you'll have to pass a &lt;code&gt;volume_type&lt;/code&gt; parameter to the creation command. Such a type has to be created beforehand and to have some backends assigned to it:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# cinder type-create lvm
# cinder type-key lvm set volume_backend_name=LVM_iSCSI
# cinder type-create nfs
# cinder type-key nfs set volume_backend_name=NFS
&lt;/pre&gt;
&lt;p&gt;Finally, to create your volumes:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# cinder create --volume_type lvm --display_name inlvm 1
&lt;/pre&gt;
&lt;p&gt;For people using the REST interface, to set any &lt;code&gt;type-key&lt;/code&gt; property, including &lt;code&gt;volume_backend_name&lt;/code&gt;, you pass that information along with the request as &lt;a class="reference external" href="https://github.com/openstack/cinder/blob/master/cinder/api/contrib/types_extra_specs.py"&gt;extra specs&lt;/a&gt;. You can list those indeed to make sure the configuration is working as expected:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#  cinder extra-specs-list
&lt;/pre&gt;
&lt;p&gt;Note that you can have backends of the same type (driver) using different names (say two LVM based backends allocating volumes in different volume groups) or you can also have backends of the same type using the same name! The scheduler is in charge of making the proper decision on how to pickup the correct backend at creation time so a few notes on the filter scheduler (enabled by default in Grizzly):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;firstly it filters the available backends (AvailabilityZoneFilter, CapacityFilter and CapabilitiesFilter are enabled by default and the backend name is matched against the capabilities)&lt;/li&gt;
&lt;li&gt;secondly weights the previously filtered backends (CapacityWeigher is the only one enabled by default)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The CapacityWeigher attributes high score to backends with the most available space, so new volumes are allocated within the backend with the more space available matching the particular name in the request.&lt;/p&gt;
</summary><category term="openstack"></category><category term="cinder"></category><category term="fedoraplanet"></category></entry><entry><title>OpenStack Cinder - Add more volume nodes</title><link href="http://giuliofidente.com/2013/04/openstack-cinder-add-more-volume-nodes.html" rel="alternate"></link><updated>2013-04-30T02:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:giuliofidente.com,2013-04-30:2013/04/openstack-cinder-add-more-volume-nodes.html</id><summary type="html">&lt;p&gt;With this being the first of a short series, I'd like to publish some articles intendend to cover the required steps to configure &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Cinder"&gt;Cinder&lt;/a&gt; (&lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; block storage service) in a mid/large deployment scenario. The idea is to discuss at least three topics: how to scale the service by adding more volume nodes; how to ensure high-availablity for the API and Scheduler sub-services; leverage the multi-backend feature landed in Grizzly.&lt;/p&gt;
&lt;p&gt;I'm starting with this post on the scaling issue first. &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Cinder"&gt;Cinder&lt;/a&gt; is composed of three main parts, the API server, the scheduler and the volume service. The volume service is some sort of abstraction layer between the API and the actual resources provider.&lt;/p&gt;
&lt;p&gt;By adding more volume nodes into the environment you will be able to increase the total offering of block storage to the tenants. Each volume node can either provide volumes by allocating them locally or on a remote container like an NFS or GlusterFS share.&lt;/p&gt;
&lt;p&gt;Some assumptions before getting into the practice:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;you're familiar with the general OpenStack architecture&lt;/li&gt;
&lt;li&gt;you have at least one Cinder node configured and working as expected&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First thing to do on the candidate node is to install the required packages. I'm running the examples on CentOS and using the &lt;a class="reference external" href="http://openstack.redhat.com"&gt;RDO&lt;/a&gt; repository which makes this step as simple as:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# yum install openstack-cinder
&lt;/pre&gt;
&lt;p&gt;If you plan to host new volumes using the locally available storage dont' forget to create a volume group called &lt;code&gt;cinder-volumes&lt;/code&gt; (the name can be configured via the &lt;code&gt;cinder_volume&lt;/code&gt; parameter). Also don't forget to configure the &lt;code&gt;tgtd&lt;/code&gt; to include the config files created dynamically by &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Cinder"&gt;Cinder&lt;/a&gt;. Add a line like the following:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
include /etc/cinder/volumes/*
&lt;/pre&gt;
&lt;p&gt;in your &lt;code&gt;/etc/tgt/targets.conf&lt;/code&gt; file. Now enable and start the &lt;code&gt;tgtd&lt;/code&gt; service:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# chkconfig tgtd on
# service tgtd start
&lt;/pre&gt;
&lt;p&gt;Amongst the three init services installed by &lt;code&gt;openstack-cinder&lt;/code&gt; you only need to run &lt;code&gt;openstack-cinder-volume&lt;/code&gt;, which gets configured in &lt;code&gt;/etc/cinder/cinder.conf&lt;/code&gt;. Configure it to connect to the existing &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Cinder"&gt;Cinder&lt;/a&gt; database (the db in use by the pre-existing node) and to the existing AMQP broker (again, in use by the pre-existing node) by setting the following:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sql_connection=mysql://cinder:${CINDER_DB_PASSWORD}&amp;#64;${CINDER_DB_HOST}/cinder
qpid_hostname=${QPIDD_BROKER}
&lt;/pre&gt;
&lt;p&gt;Set the credentials if needed and/or change the &lt;code&gt;rpc_backend&lt;/code&gt; setting if you're not using &lt;a class="reference external" href="http://qpid.apache.org/"&gt;Qpid&lt;/a&gt; as your message broker. One more setting, not really required to change but worth checking if you're using the local resources:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
iscsi_ip_address=${TGTD_IP_ADDRESS}
&lt;/pre&gt;
&lt;p&gt;That should match the public ip address of the volume node just installed. The iSCSI targets created locally using &lt;code&gt;tgtadm/tgtd&lt;/code&gt; have to be reachable by the &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Nova"&gt;Nova&lt;/a&gt; nodes. The IP address of each target is stored in the database with every volume created. The &lt;code&gt;iscsi_ip_address&lt;/code&gt; prameter sets what is the IP address to be given to the initiators.&lt;/p&gt;
&lt;p&gt;At this point you should be ready to start the volume service:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# service openstack-cinder-volume start
&lt;/pre&gt;
&lt;p&gt;Verify that it started by checking the logs (&lt;code&gt;/var/log/cinder/volume.log&lt;/code&gt;) or by issueing on any &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Cinder"&gt;Cinder&lt;/a&gt; node:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# cinder-manage host list
&lt;/pre&gt;
&lt;p&gt;you should see all of your volume nodes listed. From now on you can create new volumes as usual and they will be allocated on any of the volume nodes, keep in mind that the scheduler will default to the node with the most space available.&lt;/p&gt;
</summary><category term="openstack"></category><category term="cinder"></category><category term="fedoraplanet"></category></entry><entry><title>Getting to know and use Emacs better</title><link href="http://giuliofidente.com/2013/04/getting-to-know-and-use-emacs-better.html" rel="alternate"></link><updated>2013-04-16T18:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:giuliofidente.com,2013-04-16:2013/04/getting-to-know-and-use-emacs-better.html</id><summary type="html">&lt;p&gt;I know there are plenty of &lt;a class="reference external" href="http://emacsblog.org"&gt;Emacs related blogs&lt;/a&gt; discussing every single trick (&lt;a class="reference external" href="http://emacsredux.com/"&gt;including the easter eggs&lt;/a&gt;) so this won't be another. I don't have the skills for that either but I got to know Emacs better recently and decided to share my (hopefully nicely) commented &lt;code&gt;init.el&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;Why? Because it took me some time to find in the Emacs docs what I wanted. A readable, well commented config file would have helped so I'm sharing mine. Hopefully it'll also make it easy for you to just pickup the &lt;em&gt;things&lt;/em&gt; you like most. This config surely won't make everyone happy but, given that it's a github &lt;a class="reference external" href="http://gist.github.com/"&gt;gist&lt;/a&gt;, you're free to fork it or to add some comments providing feedback/suggestiond. Actually, feedback is very welcomed but please, keep your &lt;code&gt;Lisp&lt;/code&gt; easy to read and clean, this is for &lt;strong&gt;beginners&lt;/strong&gt;. Not to mention that I very much care about startup times!&lt;/p&gt;
&lt;script src="https://gist.github.com/giulivo/5396858.js"&gt;&lt;/script&gt;</summary><category term="emacs"></category><category term="fedoraplanet"></category></entry><entry><title>Deploy OpenStack Heat on RHEL (and derivates)</title><link href="http://giuliofidente.com/2013/04/deploy-openstack-heat-on-rhel-and-derivates.html" rel="alternate"></link><updated>2013-04-16T11:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:giuliofidente.com,2013-04-16:2013/04/deploy-openstack-heat-on-rhel-and-derivates.html</id><summary type="html">&lt;p&gt;&lt;a class="reference external" href="http://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt; provides orchestration of composite cloud applications using the CloudFormation API and templates; it is an incubated project of &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt;. Its development cycle has been integrated with &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; from the H release and, with the recent G release, it's got more mature. I want to go trough the steps needed to install and configure it as the &lt;a class="reference external" href="http://docs.openstack.org"&gt;official documentation&lt;/a&gt; is still scarce on the matter. Firstly, what it does?&lt;/p&gt;
&lt;blockquote&gt;
Heat is a service to orchestrate multiple composite cloud applications using the AWS CloudFormation template format, through both an OpenStack-native ReST API and a CloudFormation-compatible Query API.&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;UPDATE (June 2013):&lt;/strong&gt; this post has been &lt;a class="reference external" href="http://openstack.redhat.com/Deploy_Heat_and_launch_your_first_Application"&gt;published on the RDO site&lt;/a&gt; and is maintained there with up-to-date informations&lt;/p&gt;
&lt;p&gt;So you're going to deploy a composite application (made up of more than a single instance) on the cloud infrastructure, this also involves launchtime customizations of the VMs but before start, some assumptions are needed:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;I'm using CentOS 6.4 / MySQL for the examples&lt;/li&gt;
&lt;li&gt;I'm using the &lt;a class="reference external" href="http://openstack.redhat.com"&gt;RDO&lt;/a&gt; repository to install the packages&lt;/li&gt;
&lt;li&gt;The core &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; infrastructure is already configured and in good shape&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="installation"&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;If you don't have a working &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; deployment yet, I recommend you to follow the instructions on the &lt;a class="reference external" href="http://openstack.redhat.com"&gt;RDO&lt;/a&gt; site, you'll get one up and running in minutes by using &lt;a class="reference external" href="http://wiki.openstack.org/Packstack"&gt;Packstack&lt;/a&gt;. When that is finished, start by installing the required packages for &lt;a class="reference external" href="http://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt; to work:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# yum install openstack-heat-*
&lt;/pre&gt;
&lt;p&gt;You'll get four new services installed: an engine, a native api, a cloudformation compatible api, a cloudwatch compatible api. You don't have to deploy them all on a single host but for the purpose of this guide it will be fine to do so.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="configuration"&gt;
&lt;h2&gt;Configuration&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt; comes with a script which creates (and populates) the needed database for it to work but you need to know your MySQL's &lt;code&gt;root&lt;/code&gt; account password. If you've used &lt;a class="reference external" href="http://wiki.openstack.org/Packstack"&gt;Packstack&lt;/a&gt;, than that is saved as &lt;code&gt;CONFIG_MYSQL_PW&lt;/code&gt; in the answers file (&lt;code&gt;/root/packstack-answers*&lt;/code&gt; by default). Now run the prepare script:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# heat-db-setup rpm -y -r ${MYSQL_ROOT_PASSWORD} -p ${HEAT_DB_PASSWORD_OF_CHOICE}
&lt;/pre&gt;
&lt;p&gt;Check in &lt;code&gt;/etc/heat/heat-engine.conf&lt;/code&gt; that your database connection string is correct:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sql_connection = mysql://heat:${HEAT_DB_PASSWORD}&amp;#64;localhost/heat
&lt;/pre&gt;
&lt;p&gt;Now go trough the &lt;em&gt;usual&lt;/em&gt; steps needed to create a new user, service and endpoint with Keystone and don't forget to source the admin credentials before starting (which are in &lt;code&gt;/root/keystonerc_admin&lt;/code&gt; if you've used &lt;a class="reference external" href="http://wiki.openstack.org/Packstack"&gt;Packstack&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# keystone user-create --name heat --pass ${HEAT_USER_PASSWORD_OF_CHOICE}
# keystone user-role-add --user heat --role admin --tenant ${SERVICES_TENANT_NAME}
# keystone service-create --name heat --type orchestration
# keystone service-create --name heat-cfn --type cloudformation
# keystone endpoint-create --region RegionOne --service-id ${HEAT-CFN-SERVICE-ID} --publicurl &amp;quot;http://${HEAT-CFN-HOSTNAME}:8000/v1&amp;quot; --adminurl &amp;quot;http://${HEAT-CFN-HOSTNAME}:8000/v1&amp;quot; --internalurl &amp;quot;http://${HEAT-CFN-HOSTNAME}:8000/v1&amp;quot;
# keystone endpoint-create --region RegionOne --service-id ${HEAT-SERVICE-ID} --publicurl &amp;quot;http://${HEAT-HOSTNAME}:8004/v1/%(tenant_id)s&amp;quot; --adminurl &amp;quot;http://${HEAT-HOSTNAME}:8004/v1/%(tenant_id)s --internalurl &amp;quot;http://${HEAT-HOSTNAME}:8004/v1/%(tenant_id)s&amp;quot;
&lt;/pre&gt;
&lt;p&gt;Update the paste files at &lt;code&gt;/etc/heat/heat-api{,-cfn,-cloudwatch}-paste.ini&lt;/code&gt; with the credentials just created:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
admin_tenant_name = ${SERVICES_TENANT_NAME}
admin_user = heat
admin_password = ${HEAT_USER_PASSWORD}
&lt;/pre&gt;
&lt;p&gt;In there you also need to make sure that the following variables are pointing to your Keystone host (127.0.0.1 should just work if you've used &lt;a class="reference external" href="http://wiki.openstack.org/Packstack"&gt;Packstack&lt;/a&gt; as Keystone is probably installed on the same host):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
service_host = ${KEYSTONE-HOSTNAME}
auth_host = ${KEYSTONE-HOSTNAME}
auth_uri = http://${KEYSTONE-HOSTNAME}:35357/v2.0
keystone_ec2_uri = http://${KEYSTONE-HOSTNAME}:5000/v2.0/ec2tokens
&lt;/pre&gt;
&lt;p&gt;In &lt;code&gt;/etc/heat/heat-engine.conf&lt;/code&gt; you've to make instead sure that the following variables &lt;strong&gt;do not&lt;/strong&gt; point to 127.0.0.1 even though the services are actually hosted on the same system because URLs will be passed over to the VMs, which don't have them available locally:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
heat_metadata_server_url = http://${HEAT-CFN-HOSTNAME}:8000
heat_waitcondition_server_url = http://${HEAT-CFN-HOSTNAME}:8000/v1/waitcondition
heat_watch_server_url = http://${HEAT-CLOUDWATCH-HOSTNAME}:8003
&lt;/pre&gt;
&lt;p&gt;The application templates can use wait conditions and signaling for the orchestration, &lt;a class="reference external" href="http://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt; needs to create special users to receive the progress data and these users are, by default, given the role of &lt;code&gt;heat_stack_user&lt;/code&gt;. You can configure the role name in &lt;code&gt;heat-engine.conf&lt;/code&gt; or just create a so called role:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# keystone role-create --name heat_stack_user
&lt;/pre&gt;
&lt;p&gt;The configuration should now be complete and the services can be started:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# cd /etc/init.d &amp;amp;&amp;amp; for s in $(ls openstack-heat-*); do chkconfig $s on &amp;amp;&amp;amp; service $s start; done
&lt;/pre&gt;
&lt;p&gt;Make sure by checking the logs that everything was started successfully. Specifically, in case the engine service reports &lt;code&gt;ImportError: cannot import name Random&lt;/code&gt; then you're probably using an old version of &lt;code&gt;pycrypto&lt;/code&gt;. A fix has been merged upstream to workaround the issue. It's &lt;a class="reference external" href="https://review.openstack.org/#/c/26759/"&gt;a trivial change&lt;/a&gt; which you can apply manually to &lt;code&gt;heat/common/crypt.py&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="get-the-demo-files"&gt;
&lt;h2&gt;Get the demo files&lt;/h2&gt;
&lt;p&gt;It is time now to launch your first multi-instance cloud application! There are a number of sample templates available in the &lt;a class="reference external" href="https://github.com/openstack/heat"&gt;github repo&lt;/a&gt;, download the composed Wordpress example with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# wget https://raw.github.com/openstack/heat-templates/master/cfn/WordPress_Composed_Instances.template
&lt;/pre&gt;
&lt;p&gt;&lt;a class="reference external" href="http://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt; can use the templates distributed for &lt;a class="reference external" href="http://aws.amazon.com/cloudformation/"&gt;AWS CloudFormation&lt;/a&gt;. These expect you to have a well known set of flavor types defined while the default flavors available in &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; don't match strictly such a collection. To avoid the need of hack the templates, you can use an helpful script which recreates in &lt;a class="reference external" href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; the same flavors from AWS:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# curl https://raw.github.com/openstack/heat/master/tools/nova_create_flavors.sh | bash
&lt;/pre&gt;
&lt;p&gt;Every template also provides you with a list of usable distros and map these into an AMI string, for each arch. You will have to populate Glance with an image matching the AMI string that the template file is expecting to find.&lt;/p&gt;
&lt;p&gt;There is a tool, called &lt;a class="reference external" href="https://github.com/sdake/heat-jeos"&gt;heat-jeos&lt;/a&gt;, which can be used to create the JEOS images and upload them to Glance but there is also a collection of prebuilt images at: &lt;a class="reference external" href="http://fedorapeople.org/groups/heat/prebuilt-jeos-images/"&gt;http://fedorapeople.org/groups/heat/prebuilt-jeos-images/&lt;/a&gt; so I suggest you to just download one from &lt;code&gt;F17-x86_64-cfntools.qcow2&lt;/code&gt; or &lt;code&gt;U10-x86_64-cfntools.qcow2&lt;/code&gt; (which are referred by many if not all the templates available in the Heat's repo). To upload the F17 x86_64 image in Glance:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# glance image-create --name F17-x86_64-cfntools --disk-format qcow2 --container-format bare --is-public True --copy-from http://fedorapeople.org/groups/heat/prebuilt-jeos-images/F17-x86_64-cfntools.qcow2
&lt;/pre&gt;
&lt;p&gt;While that is downloading, create a new keypair or upload you public key in nova to make sure you'll be able to login on the VMs using SSH:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# nova keypair-add --pub_key ~/.ssh/id_rsa.pub userkey
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="launch"&gt;
&lt;h2&gt;Launch!&lt;/h2&gt;
&lt;p&gt;It is time for the real fun now, launch your first composed application with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# heat-cfn create wordpress --template-file=WordPress_Composed_Instances.template --parameters=&amp;quot;DBUsername=wp;DBPassword=wp;KeyName=userkey;LinuxDistribution=F17&amp;quot;
&lt;/pre&gt;
&lt;p&gt;More parameters could have passed, note for instance the LinuxDistribution parameter discussed above. Now the interesting stuff:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# heat-cfn list
# heat-cfn event-list wordpress
&lt;/pre&gt;
&lt;p&gt;After the VMs are launched, the mysql/httpd/wordpress installation and configuration begins, the process is driven by the &lt;code&gt;cfntools&lt;/code&gt;, installed in the VMs images. It will take quite some time, despite the &lt;code&gt;event-list&lt;/code&gt; reporting completion for the WordPress install too early (there is signaling, via &lt;code&gt;cfn-signal&lt;/code&gt;, only in the MySQL template). You can login on the instances and check the logs or just use &lt;code&gt;ps&lt;/code&gt; to see how things are going. After some minutes the setup should be finished:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# heat-cfn describe wordpress
# wget ${WebsiteURL} // that is an URL from the previous command!
&lt;/pre&gt;
&lt;p&gt;If anything goes wrong, check the logs at &lt;code&gt;/var/log/heat/engine.log&lt;/code&gt; or look at the scripts passed as &lt;code&gt;UserData&lt;/code&gt; to the instances, these should be found in &lt;code&gt;/var/lib/cloud/data/&lt;/code&gt;. Time to hack your very own template and delete the test deployment! :)&lt;/p&gt;
&lt;/div&gt;
</summary><category term="openstack"></category><category term="heat"></category><category term="fedoraplanet"></category><category term="rhel"></category><category term="centos"></category></entry><entry><title>1366x768 is not allowed in the EDID block. Here's how to write your XOrg modeline.</title><link href="http://giuliofidente.com/2012/10/1366x768-is-not-allowed-in-the-edid-block-heres-how-to-write-your-xorg-modeline.html" rel="alternate"></link><updated>2012-10-09T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:giuliofidente.com,2012-10-09:2012/10/1366x768-is-not-allowed-in-the-edid-block-heres-how-to-write-your-xorg-modeline.html</id><summary type="html">&lt;p&gt;Looks like there are many LCD panels/TVs out there with a native resolution of 1366x768. That is indeed a very close approximation to the expected 16:9 rectangle, except XOrg keeps showing you a resolution of 1360x768 (or 1368x768) instead of the native 1366x768. Why? Because 1366 is not divisible by 8 and that's not valid in an EDID block. &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Extended_display_identification_data#Limitations"&gt;Learn more on wikipedia&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You need a custom &lt;a class="reference external" href="http://en.wikipedia.org/wiki/XFree86_Modeline"&gt;modeline in your xorg.conf&lt;/a&gt; file for that. The NVIDIA drivers also have some &lt;a class="reference external" href="http://us.download.nvidia.com/XFree86/Linux-x86_64/304.43/README/xconfigoptions.html"&gt;ModeValidation&lt;/a&gt; setting which needs some attention. Let's start with the last one, you need to add the following (in the Screen section):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Option &amp;quot;ModeValidation&amp;quot; &amp;quot;AllowNonEdidModes, NoWidthAlignmentCheck&amp;quot;
&lt;/pre&gt;
&lt;p&gt;To make XOrg log files more verbose, you may also want to add the following:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Option &amp;quot;ModeDebug&amp;quot; &amp;quot;True&amp;quot;
&lt;/pre&gt;
&lt;p&gt;And what about the modeline? So &lt;a class="reference external" href="http://howto-pages.org/ModeLines/"&gt;this guy wrote a lot about it&lt;/a&gt; but for our purposes, let's just start with &lt;a class="reference external" href="http://www.xfree86.org/current/xvidtune.1.html"&gt;xvidtune&lt;/a&gt; to check for the current settings:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ xvidtune -show
&amp;quot;1360x768&amp;quot; 84.75 1360 1432 1568 1776 768 771 776 798 -hsync +vsync
&lt;/pre&gt;
&lt;p&gt;After the modeline 'description' (whis is 1360x768), the first number you see represents the pixel clock speed. The remaining eight numbers are two groups of four numbers intended to set the horizontal and vertical resolution. The interesting thing is that you can get your hrefresh and vrefresh value with a simple formula: &lt;code&gt;hrefresh = 84.75/1776&lt;/code&gt; and &lt;code&gt;vrefresh = 84.75/(1776*798)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now, on my LCD manual I had the following valuable informations:&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;1360*768&lt;/dt&gt;
&lt;dd&gt;47.72 59.8 84.75&lt;/dd&gt;
&lt;dt&gt;1366*768&lt;/dt&gt;
&lt;dd&gt;47.56 59.6 84.75&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Those are hrefresh, vrefresh and pixel clock. Let's put those in the modeline adding some more small changes:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;quot;1366x768&amp;quot; 84.75 1366 1438 1574 1782 768 771 776 798 -hsync +vsync
&lt;/pre&gt;
&lt;p&gt;Now here is how the new numbers were found:&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;84.75&lt;/dt&gt;
&lt;dd&gt;is the pixel clock and remains the same as per service manual&lt;/dd&gt;
&lt;dt&gt;1360 became 1366&lt;/dt&gt;
&lt;dd&gt;that's the hresolution we want&lt;/dd&gt;
&lt;dt&gt;1776 became 1782&lt;/dt&gt;
&lt;dd&gt;that is what we need to get the 47.56 hrefresh and 59.6 vrefresh values indicated in the service manual, check yourself with the formula &lt;code&gt;84.75/1782 ~= 47.56&lt;/code&gt; and &lt;code&gt;84.75/(1782\*798) ~= 59.6&lt;/code&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Also, from the initial xvidtune output, the numbers 1432 and 1568 represent some delay, measured in pixels pictured past the viewable area, at the defined pixel clock speed. They are used to set &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Analog_television"&gt;front porch, sync pulse and back porch&lt;/a&gt;; by using 1360 as the number of horizontal pixels you get the following:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(1432-1360)/84.75 = 0.84us black on right side
(1568-1432)/84.75 = 1.60us sync pulse width
(1776-1568)/84.75 = 2.54us black on left side
&lt;/pre&gt;
&lt;p&gt;Now use 1366 as the number of horizontal pixels and keep the delay unchanged:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
(1438-1366)/84.75 = 0.84us black on right side
(1574-1438)/84.75 = 1.60us sync pulse width
(1782-1574)/84.75 = 2.54us black on left side
&lt;/pre&gt;
&lt;p&gt;Finally, for this blog post all the values I'm using refer to the LG 37LG3000. Enjoy!&lt;/p&gt;
</summary><category term="1366x768"></category><category term="xorg modeline"></category><category term="linux"></category><category term="fedoraplanet"></category><category term="nvidia"></category></entry><entry><title>My attempts at MapReduce using MongoDB</title><link href="http://giuliofidente.com/2012/06/my-attempts-at-mapreduce-using-mongodb.html" rel="alternate"></link><updated>2012-06-14T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:giuliofidente.com,2012-06-14:2012/06/my-attempts-at-mapreduce-using-mongodb.html</id><summary type="html">&lt;p&gt;I was sorting a tree in my (python) webapp instead of having the database to do it for me. This is how I moved it back to the database by using a &lt;a class="reference external" href="http://en.wikipedia.org/wiki/MapReduce"&gt;MapReduce&lt;/a&gt; job. I had a collection structured like the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;...&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;feed_oid&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;4fd268d2ab87b2d8927d7eee&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;title&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;blah blah&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;updated&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1339702524&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;watchers&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;4fd276fc66224c1ee8000006&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Such a collection is called &lt;code&gt;articles&lt;/code&gt; and in there I get a document for every article published by an rss feed. &lt;code&gt;feed_oid&lt;/code&gt; is an identifier I assign to every rss feed that I'm crawling and &lt;code&gt;watchers&lt;/code&gt; contains a list of identifiers assigned to the people voting on such an article.&lt;/p&gt;
&lt;p&gt;I wanted to find out the number of times a particular watcher appeared in the full list of articles and than, group that by the rss feed, so that I could end up with the number of times a person voted on articles published by the same feed.&lt;/p&gt;
&lt;p&gt;The following are my map and reduce functions:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;emit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;feed_oid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;oids&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;vals&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;v&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;vals&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;sum&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nx"&gt;vals&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;v&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The map function is called for every object matching the query filter, so it gets access to 'this'. The reduce function receives an array of values (all set to 1, by my map function) for every feed_oid emitted.&lt;/p&gt;
&lt;p&gt;Here is how I spawn the MapReduce job (querying by the watcher id):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;articles&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;mapReduce&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;query&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;watchers&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;4fd276fc66224c1ee8000006&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="nx"&gt;out&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;mapreduceout&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The results:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;mapreduceout&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;find&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;4fd268d2ab87b2d8927d7eea&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;value&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;_id&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;4fd268d2ab87b2d8927d7eee&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;value&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Looks like this guy voted 4 times on articles appeared on the feed 4fd268d2ab87b2d8927d7eee and 1 4fd268d2ab87b2d8927d7eea :P&lt;/p&gt;
</summary><category term="mapreduce"></category><category term="fedoraplanet"></category><category term="mongodb"></category></entry><entry><title>YUM history (!)</title><link href="http://giuliofidente.com/2012/04/yum-history.html" rel="alternate"></link><updated>2012-04-26T00:00:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:giuliofidente.com,2012-04-26:2012/04/yum-history.html</id><summary type="html">&lt;p&gt;While browsing the &lt;a class="reference external" href="http://yum.baseurl.org/"&gt;YUM&lt;/a&gt; man page for some details about the query command I happened to find one of my most wanted feature in a package manager! YUM has some &lt;a class="reference external" href="http://docs.fedoraproject.org/en-US/Fedora/16/html/System_Administrators_Guide/sec-Yum-Transaction_History.html"&gt;history&lt;/a&gt; command which allows for investigation of past transactions and even &lt;strong&gt;undo&lt;/strong&gt; or &lt;strong&gt;rollback&lt;/strong&gt; actions. Epic. I frequently find myself going through install/uninstall steps which not only mess around but I tend to forget about the installed and now unneeded deps.&lt;/p&gt;
&lt;p&gt;I'll go through a basic &lt;code&gt;history&lt;/code&gt; usage example but there is a lot more to discover. Consider the following command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# yum install anjuta
...
Installed:
 anjuta.i686 1:3.2.0-1.fc16

Dependency Installed:
 apr.i686 0:1.4.6-1.fc16
 apr-util.i686 0:1.3.12-1.fc16
 autogen.i686 0:5.9.4-8.fc15
 autogen-libopts.i686 0:5.9.4-8.fc15
 devhelp.i686 1:3.2.0-1.fc16
 glade3-libgladeui.i686 1:3.10.0-6.fc16
 guile.i686 5:1.8.8-3.fc16
 libgda.i686 1:4.2.8-2.fc16
 libgda-sqlite.i686 1:4.2.8-2.fc16
 libgdl.i686 1:3.2.0-1.fc16
 sqlite-devel.i686 0:3.7.7.1-1.fc16
 subversion-libs.i686 0:1.6.17-5.fc16
 vala.i686 0:0.14.2-3.fc16
&lt;/pre&gt;
&lt;p&gt;Many dependencies have been installed and you surely won't remember all of them when later removing anjuta. You could go through some cleaning session using &lt;code&gt;package-cleanup&lt;/code&gt;, from
&lt;a class="reference external" href="http://yum.baseurl.org/wiki/YumUtils"&gt;yum-utils&lt;/a&gt; but that isn't really intended to revert back your system status, it will just help you remove unneeded packages. Here's instead what &lt;code&gt;history&lt;/code&gt; can do for you:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# yum history list anjuta
Loaded plugins: downloadonly, langpacks, presto, refresh-packagekit
ID   | Command line       | Date and time    | Action(s)  | Altered
-------------------------------------------------------------------
 172 | install anjuta     | 2012-04-26 09:02 | Install    |   14

# yum history info 172
Loaded plugins: downloadonly, langpacks, presto, refresh-packagekit
Transaction ID : 172
Begin time     : Thu Apr 26 09:02:57 2012
Begin rpmdb    : 1225:459cfe1ee50fe38d585386f265e6647ab8d4b5a9
End time       :            09:03:19 2012 (22 seconds)
End rpmdb      : 1239:9784f29b6dff78d982e401bfa5e4cbd9620c47ed
User           : Giulio Fidente
Return-Code    : Success
Command Line   : install anjuta
Transaction performed with:
    Installed     rpm-4.9.1.3-1.fc16.i686               &amp;#64;updates
    Installed     yum-3.4.3-23.fc16.noarch              &amp;#64;updates
    Installed     yum-metadata-parser-1.1.4-5.fc16.i686 &amp;#64;koji-overrides
Packages Altered:
    Install     anjuta-1:3.2.0-1.fc16.i686             &amp;#64;fedora
    Dep-Install apr-1.4.6-1.fc16.i686                  &amp;#64;updates
    Dep-Install apr-util-1.3.12-1.fc16.i686            &amp;#64;fedora
    Dep-Install autogen-5.9.4-8.fc15.i686              &amp;#64;fedora
    Dep-Install autogen-libopts-5.9.4-8.fc15.i686      &amp;#64;fedora
    Dep-Install devhelp-1:3.2.0-1.fc16.i686            &amp;#64;fedora
    Dep-Install glade3-libgladeui-1:3.10.0-6.fc16.i686 &amp;#64;updates
    Dep-Install guile-5:1.8.8-3.fc16.i686              &amp;#64;fedora
    Dep-Install libgda-1:4.2.8-2.fc16.i686             &amp;#64;updates
    Dep-Install libgda-sqlite-1:4.2.8-2.fc16.i686      &amp;#64;updates
    Dep-Install libgdl-1:3.2.0-1.fc16.i686             &amp;#64;fedora
    Dep-Install sqlite-devel-3.7.7.1-1.fc16.i686       &amp;#64;fedora
    Dep-Install subversion-libs-1.6.17-5.fc16.i686     &amp;#64;fedora
    Dep-Install vala-0.14.2-3.fc16.i686                &amp;#64;updates

# yum history undo 172
...
Removed:
 anjuta.i686 1:3.2.0-1.fc16
 apr.i686 0:1.4.6-1.fc16
 apr-util.i686 0:1.3.12-1.fc16
 autogen.i686 0:5.9.4-8.fc15
 autogen-libopts.i686 0:5.9.4-8.fc15
 devhelp.i686 1:3.2.0-1.fc16
 glade3-libgladeui.i686 1:3.10.0-6.f16
 guile.i686 5:1.8.8-3.fc16
 libgda.i686 1:4.2.8-2.fc16
 libgda-sqlite.i686 1:4.2.8-2.fc16
 libgdl.i686 1:3.2.0-1.fc16
 sqlite-devel.i686 0:3.7.7.1-1.fc16
 subversion-libs.i686 0:1.6.17-5.fc16
 vala.i686 0:0.14.2-3.fc16
&lt;/pre&gt;
&lt;p&gt;Great isn't it? And there is a lot more! The &lt;code&gt;rollback&lt;/code&gt; command will revert back the status of the &lt;strong&gt;whole&lt;/strong&gt; software packages installed at the time of the transaction ID.&lt;/p&gt;
</summary><category term="fedora"></category><category term="fedoraplanet"></category><category term="yum"></category></entry><entry><title>OS X Network Install using Linux (updates)</title><link href="http://giuliofidente.com/2009/01/os-x-network-install-using-linux-updates.html" rel="alternate"></link><updated>2009-01-06T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:giuliofidente.com,2009-01-06:2009/01/os-x-network-install-using-linux-updates.html</id><summary type="html">&lt;p&gt;Do you still remember &lt;a class="reference external" href="http://giuliofidente.com/2006/11/os-x-network-install-using-linux.html"&gt;this&lt;/a&gt;? It was a good post about the OS X install via the network using a GNU/Linux install server. I went back to read and use it after a few days to install the version 10.5 (leopard) of OS X and it worked well but there's a couple of things missing in that post which I'd like to share here.&lt;/p&gt;
&lt;p&gt;The problems were mainly in mounting the leopard disc. If you try to do that on a GNU/Linux system you should only see some files about bootcamp, it is indeed a double format dvd which includes two sections, one is iso9660 formatted and another is hfs+ formatted. To find the files I mentioned, you'll have to mount the hfs+ formatted section ... which is hidden but you can find it using this very helpful link: &lt;a class="reference external" href="http://www.64lines.com/mounting-hfs-plus"&gt;Mounting HFS+ Hybrid Disks on Linux&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also, because of the additional steps, when you're at this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
dd if=/dev/hdc of=/tftpboot/macosx.img
&lt;/pre&gt;
&lt;p&gt;you'll have to replace /dev/hdc with the /dev/loop0 device created by the instructions linked before.&lt;/p&gt;
</summary><category term="osx network install"></category><category term="linux network install"></category><category term="leopard network install"></category><category term="fedoraplanet"></category></entry><entry><title>OS X Network Install using Linux</title><link href="http://giuliofidente.com/2006/11/os-x-network-install-using-linux.html" rel="alternate"></link><updated>2006-11-01T00:00:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:giuliofidente.com,2006-11-01:2006/11/os-x-network-install-using-linux.html</id><summary type="html">&lt;p&gt;The title says it all. We're going to install an OS X client via network using a GNU/Linux box as DHCP/TFTP/NFS server.&lt;/p&gt;
&lt;p&gt;First you'll want to setup your DHCP, TFTP and NFS server.&lt;/p&gt;
&lt;p&gt;The default location for the TFTP server root on my system was &lt;code&gt;/tftpboot&lt;/code&gt;. It may be different on other distro so change at will. This directory is where we're going to put all the important files. Three files come from the OS X disc (although you'll have to rename two of them) and the fourth is a simple image of the OS X disc itself.&lt;/p&gt;
&lt;p&gt;Mount the Mac OS X disc and copy and rename the following files into your TFTP server root&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cp /cdrom/System/Library/CoreServices/BootX /tftpboot/BootX
cp /cdrom/mach\_kernel /tftpboot/mach.macosx
cp /cdrom/System/Library/Extensions.mkext /tftpboot/mach.macosx.mkext
&lt;/pre&gt;
&lt;p&gt;Unmount and make an image of the install disc in the TFTP server root&lt;/p&gt;
&lt;pre class="literal-block"&gt;
dd if=/dev/hdc of=/tftpboot/macosx.img
&lt;/pre&gt;
&lt;p&gt;On your NFS server, you'll want to modify &lt;code&gt;/etc/exports&lt;/code&gt; to include something like the following&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/tftpboot/ mac-ip-address(ro,insecure)
&lt;/pre&gt;
&lt;p&gt;where mac-ip-address is the mac address assigned to your mac manually (see step 7) or by the DHCP server.&lt;/p&gt;
&lt;p&gt;At this point you'll want to start the TFTP server and NFS services.&lt;/p&gt;
&lt;p&gt;Boot into the open firmware (by holding command+option+O+F) and issue the following commands&lt;/p&gt;
&lt;pre class="literal-block"&gt;
setenv boot-device enet:ip-address-of-linux-server,BootX
setenv boot-args rp=nfs:ip-address-of-linux-server:/tftpboot/:macosx.img
boot
&lt;/pre&gt;
&lt;p&gt;where ip-address-of-linux-server is... self-explanatory.&lt;/p&gt;
&lt;p&gt;The well familiar Mac boot sequence should start except now you have a little spinning world as logo while it tries to make a connection to the Linux server. You'll probably want to hold command+V while booting the Mac to see what's actually happening and to ensure the whole process is going smoothly.&lt;/p&gt;
&lt;p&gt;I hope it helped!&lt;/p&gt;
</summary><category term="osx network install"></category><category term="linux network install"></category><category term="leopard network install"></category><category term="fedoraplanet"></category></entry></feed>