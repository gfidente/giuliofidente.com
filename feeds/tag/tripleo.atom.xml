<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Giulio Fidente</title><link href="http://giuliofidente.com/" rel="alternate"></link><link href="http://giuliofidente.com/feeds/tag/tripleo.atom.xml" rel="self"></link><id>http://giuliofidente.com/</id><updated>2015-11-03T17:30:00+01:00</updated><entry><title>OpenStack summit in Tokyo and TripleO</title><link href="http://giuliofidente.com/2015/11/openstack-summit-in-tokyo-and-tripleo.html" rel="alternate"></link><updated>2015-11-03T17:30:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:giuliofidente.com,2015-11-03:2015/11/openstack-summit-in-tokyo-and-tripleo.html</id><summary type="html">&lt;p&gt;&lt;a class="reference external" href="https://www.openstack.org/summit/tokyo-2015/"&gt;OpenStack summit Tokyo&lt;/a&gt; anyone? I've been there and thought it was a very well organized event, in a nice location. Every minute together with peers seemed worth it to me. This said, let's talk about the actual sessions. I spent most of my time at the TripleO and Heat sessions, with a little detour on Magnum. Plus some booth crawling.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;TripleO&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;We had three sessions and a full day meetup. The first discussed the recent work done to allow for the deployment of OpenStack in containers, using TripleO; the changes to deploy the compute nodes and a majority of the controller roles in containers are up for review, which is great; some notes can be found in the &lt;a class="reference external" href="https://etherpad.openstack.org/p/tripleo-mitaka-containers"&gt;tripleo-mitaka-containers&lt;/a&gt; pad. It was very nice for me to see the TripleO bits delivering on the promise of being flexibile; deploying in containers requires minimal changes to the core tools and yet inherits important features like network isolation and support for Ceph.&lt;/p&gt;
&lt;p&gt;Another session was on upgrades, which isn't a trivial goal as it pushes on both Heat and Puppet. The proposed plan is to start with a CI job attempting to upgrade an overcloud from the stable branch to the master branch; more in the &lt;a class="reference external" href="https://etherpad.openstack.org/p/tripleo-kilo-to-liberty-upgrades"&gt;tripleo-kilo-to-liberty-upgrades&lt;/a&gt; pad. I will hopefully write more about this topic in future posts.&lt;/p&gt;
&lt;p&gt;There has also been a session on the CLI and UI clients. Again, not a simple problem because the Heat templates are constantly ongoing refactor to implement new features and because putting too much business logic into the client limited our flexibility in the past. We'll probably see a shared library for the newer CLI/UI, with less business logic and probably a REST API, more in the &lt;a class="reference external" href="https://etherpad.openstack.org/p/tripleo-mitaka-restapi"&gt;tripleo-mitaka-restapi&lt;/a&gt; pad.&lt;/p&gt;
&lt;p class="last"&gt;Then the community meetup on Friday covered a few additional topics. We reviewed the status of the CI with ideas for more jobs, discussed some ideas to provision the puppet modules via Heat instead of shipping them with the images, collected lots of good feedback from actual OpenStack operators and, last but not least, discussed the recent work from &lt;a class="reference external" href="https://github.com/dprince/"&gt;Dan Prince&lt;/a&gt; to have composable roles. Kudos to Dan on the composable roles which also seems to work pretty well with the effort to containerize the deployment. Notes about the community meetup are in the &lt;a class="reference external" href="https://etherpad.openstack.org/p/tripleo-mitaka-meetup"&gt;tripleo-mitaka-meetup&lt;/a&gt; pad.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Heat&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;I've joined only those sessions were I could at least understand the topics and yet there is quite a lot to write about. First an interesting session focused on a problem with dependencies across nested stacks, which we make large us of in TripleO. Both the issue and the consequences are much easier to understand with a picture than with words. &lt;a class="reference external" href="http://www.zerobanana.com/"&gt;Zane Bitter&lt;/a&gt; had indeed prepared some &lt;em&gt;demo&lt;/em&gt; material for the session, including pictures, which should be linked from the &lt;a class="reference external" href="https://etherpad.openstack.org/p/mitaka-heat-break-stack-barrier"&gt;mitaka-heat-break-stack-barrier&lt;/a&gt; pad.&lt;/p&gt;
&lt;p&gt;Then a session to discuss issues affecting large stack deployments. Major points for discussion were of three types: token timeouts, batching of operations and resources status polling, with resources polling being probably the hardest to cope with. More in the &lt;a class="reference external" href="https://etherpad.openstack.org/p/mitaka-heat-large-stacks"&gt;mitaka-heat-large-stacks&lt;/a&gt; pad.&lt;/p&gt;
&lt;p&gt;Then a session to collect input from users and ops. My proposal here was for the introduction of 'immutable resources' where resources with such a proerty wouldn't get deleted or updated during a stack update. One proposed solution for this is a warning message, outputted by the stack validation process, in case of resources deletion. More on this and on the session in general in the &lt;a class="reference external" href="https://etherpad.openstack.org/p/mitaka-heat-user-ops"&gt;mitaka-heat-user-ops&lt;/a&gt; pad.&lt;/p&gt;
&lt;p class="last"&gt;There has also been an interesting conversation about the changes from a spec meant to introduce support for &lt;a class="reference external" href="http://specs.openstack.org/openstack/heat-specs/specs/liberty/external_resource.html"&gt;external resources&lt;/a&gt;, which is something TripleO could use soon.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Magnum&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;The Magnum project seems to be facing some of the problems which TripleO faced in past as well, in relation to the Heat templates. The goal seems to be to customize the templates based on the input parameters; I joined the session to learn more about the Magnum approach and the proposed solutions.&lt;/p&gt;
&lt;p class="last"&gt;It seems to me that while TripleO relies on actual Heat features to allow for different implementations of the same resource, via resource registry, Magnum is working instead on a sort of pre-processor (powered by Jinja) which generates Heat templates using conditionals and includes from the Jinja language. More on this is in the &lt;a class="reference external" href="https://bugs.launchpad.net/magnum/+bug/1501045"&gt;launchpad bug 1501045&lt;/a&gt;.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Who said installers?&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;It was nice to see TripleO mentioned in at least two more sessions, one where Mirantis directly compared Fuel to the Red Hat OpenStack Platform Director and another where &lt;a class="reference external" href="https://openstacksummitoctober2015tokyo.sched.org/event/7032267fad9f6f0e5242093d17d59d64"&gt;four different automated installers were reviewed&lt;/a&gt;. Each had its moments.&lt;/p&gt;
&lt;p class="last"&gt;I think one good thing about TripleO is that it is pretty flexible and offers some capabilities to maintain the environment even after the initial installation; hopefully both will make it interesting to many.&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;RDO meetup&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;We had a meetup for the &lt;a class="reference external" href="http://rdoproject.org/"&gt;RDO&lt;/a&gt; project and it cleared up a lot of questions on how the packages are built and tested for both the trunk and the stable branches. Good news is that users should be able now to try TripleO, on CentOS, with the latest RDO bits.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Now, what about the event? Well, as an ATC, I have two things to say about the event more in general. First, &lt;strong&gt;I'd really like the design summit to start on Tuesday&lt;/strong&gt;. Simply put, there are so many sessions going on that it is impossible to join anything out of the most immediate interests. My thinking is that one more day could at least lower parallelism!&lt;/p&gt;
&lt;p&gt;Another comment is, please &lt;strong&gt;make the keynotes a little less marketish&lt;/strong&gt;. I know the circus runs on actual money but my feeling is that the keynotes, on both Tuesday and Wednesday, left some sessions go a little too far into the product marketing area when they were probably supposed to present an actual OpenStack use case.&lt;/p&gt;
&lt;img alt="OpenStack summit Ticket" class="align-center" src="http://giuliofidente.com/images/ticket_os2015.png" /&gt;
&lt;p&gt;Last but not least, it was great to have some time to meet face to face peers and coworkers from all over the world. Including some who are &lt;em&gt;not exactly&lt;/em&gt; peers, like &lt;a class="reference external" href="https://www.linkedin.com/in/matthicksj"&gt;Matt&lt;/a&gt;, to whom I ended up asking if he was a newcome to the TripleO project during dinner. I'm sure next time I will remember and do better.&lt;/p&gt;
</summary><category term="openstack"></category><category term="events"></category><category term="tripleo"></category><category term="fedoraplanet"></category></entry><entry><title>Ceph for Cinder in TripleO</title><link href="http://giuliofidente.com/2015/01/ceph-for-cinder-in-tripleo.html" rel="alternate"></link><updated>2015-01-06T17:15:00+01:00</updated><author><name>Giulio Fidente</name></author><id>tag:giuliofidente.com,2015-01-06:2015/01/ceph-for-cinder-in-tripleo.html</id><summary type="html">&lt;p&gt;A wrap up on the status of TripleO's Cinder HA spec. First, a link to the &lt;a class="reference external" href="https://blueprints.launchpad.net/tripleo/+spec/tripleo-kilo-cinder-ha"&gt;cinder-ha blueprint&lt;/a&gt;, where you can find even more links, to the actual spec (under review) and the code changes (again, still under review). Intent of the blueprint is for the &lt;a class="reference external" href="https://wiki.openstack.org/wiki/TripleO"&gt;TripleO&lt;/a&gt; deployments to keep Cinder volumes available and Cinder operational in case of failures of any node.&lt;/p&gt;
&lt;p&gt;This said, should $subject sound interesting to you, beware the code still needs reviews, probably polishing and surely more features ... so take this post as a call for help as well! Now some details.&lt;/p&gt;
&lt;p&gt;For Cinder to remain operational, in &lt;a class="reference external" href="https://wiki.openstack.org/wiki/TripleO"&gt;TripleO&lt;/a&gt; we deploy the &lt;code&gt;cinder-{api,schduler,volume}&lt;/code&gt; services on all controller nodes (as it was even before the proposed spec) but we also customize the &lt;code&gt;host&lt;/code&gt; setting so that all instances of &lt;code&gt;cinder-volume&lt;/code&gt; will share an identical identifier. This is so that all instances can perform operations on all volumes, otherwise, the particular host which created a volume would be the only one capable of performing further operations on it. This exposed some potential issues with Cinder due to concurrent mutation of same resource from multiple nodes and they already are taken care of, in Cinder, with the &lt;a class="reference external" href="https://blueprints.launchpad.net/cinder/+spec/cinder-state-enforcer"&gt;state-enforcer blueprint&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Then, for the volumes to remain available, &lt;a class="reference external" href="https://wiki.openstack.org/wiki/TripleO"&gt;TripleO&lt;/a&gt; will deploy a Ceph cluster together with the OpenStack components, to be used as a backend for Cinder. Each and every controller will host a Ceph monitor while an arbitrary number of additional nodes can be configured as Ceph OSDs. The basic idea is that by doing so people will be able to scale out the number of controllers and/or data nodes independently, in an attempt to suit the needs for more space or more CPU resources depending on the use case. In addition to that, network partitioning should also be easy to achieve as traffic from Nova nodes will be directed to the OSDs nodes only for volumes I/O, not to the controllers. Note though that the existing implementation &lt;strong&gt;does not yet&lt;/strong&gt; implement support for the network partitioning but, on a good note, &lt;strong&gt;it does&lt;/strong&gt; use cephx already to secure access to data.&lt;/p&gt;
&lt;p&gt;As of today, assuming you checkout by yourself, as linked from the &lt;a class="reference external" href="https://blueprints.launchpad.net/tripleo/+spec/tripleo-kilo-cinder-ha"&gt;cinder-ha blueprint&lt;/a&gt;, the needed &lt;a class="reference external" href="https://wiki.openstack.org/wiki/TripleO"&gt;TripleO&lt;/a&gt; changes, everything should &lt;em&gt;just work&lt;/em&gt; by setting some value &amp;gt; 0 for the &lt;code&gt;CEPHSTORAGESCALE&lt;/code&gt; env variable, which represents the number of OSD nodes you want to deploy. Should you need it, in the Heat templates it is possible to customize a number of useful Ceph settings, like the number of replicas for the data (needs to be lower than the number of OSD nodes). Now go try it out and come back with some feedback! :)&lt;/p&gt;
</summary><category term="openstack"></category><category term="cinder"></category><category term="tripleo"></category><category term="ceph"></category><category term="high availability"></category><category term="fedoraplanet"></category></entry><entry><title>TripleO vs OpenStack HA</title><link href="http://giuliofidente.com/2014/08/tripleo-vs-openstack-ha.html" rel="alternate"></link><updated>2014-08-21T15:02:00+02:00</updated><author><name>Giulio Fidente</name></author><id>tag:giuliofidente.com,2014-08-21:2014/08/tripleo-vs-openstack-ha.html</id><summary type="html">&lt;p&gt;One of the topics discussed during the &lt;a class="reference external" href="https://wiki.openstack.org/wiki/TripleO"&gt;TripleO&lt;/a&gt; mid-cycle meetup in RDU was our status in relation to deploying OpenStack in a highly available manner. This had been worked on for some time and recently reached a usable state.&lt;/p&gt;
&lt;p&gt;Majority of complications seem to come from two factors: 1) we need to guarantee availability of external services too, like the database and the message broker, which aren't exactly designed for a scale-out scenario, 2) despite the OpenStack services being designed around a scale-out concept, while attempting to achieve that in &lt;a class="reference external" href="https://wiki.openstack.org/wiki/TripleO"&gt;TripleO&lt;/a&gt; we spotted a number of weak angles, some of which could be worked around, others instead still need some changes in the core service. You're encouraged to try what we have available today and help with the rest.&lt;/p&gt;
&lt;p&gt;So to try out OpenStack HA with &lt;a class="reference external" href="https://wiki.openstack.org/wiki/TripleO"&gt;TripleO&lt;/a&gt; you just set a number &amp;gt;= 3 for &lt;code&gt;OVERCLOUD_CONTROLSCALE&lt;/code&gt; and continue with &lt;a class="reference external" href="http://docs.openstack.org/developer/tripleo-incubator/devtest.html"&gt;devtest&lt;/a&gt; as usual. Nodes will be configured appropriately:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
export OVERCLOUD_CONTROLSCALE=3
source scripts/devtest_variables.sh
...
&lt;/pre&gt;
&lt;p&gt;Don't forget this is only tested on a few distros for now, I'd pick some Fedora 20.&lt;/p&gt;
&lt;p&gt;On the controller nodes, MariaDB with Galera (for Fedora) is going to provide for a reliable SQL. There is still some work in progress to make sure the Galera cluster can be restarted correctly should all the controllers go down at the same time but, for single node failures, this should be safe to use.&lt;/p&gt;
&lt;p&gt;RabbitMQ nodes are clustered and balanced (via HAProxy), queues replicated.&lt;/p&gt;
&lt;p&gt;And with regards to the OpenStack services, these are configured in a balancing manner (again, using HAProxy) except for those cases where this wouldn't have worked, notably the Neutron L3 agent and the Ceilometer Central agent, yet these are under control via Pacemaker and a single instance is expected to be running at all times. Cinder instead remains uncovered as volumes would require a shared storage for proper HA. A spec has been proposed for this though.&lt;/p&gt;
&lt;p&gt;Also, behind the scenes, the &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt; template language addon shipped as &lt;em&gt;merge.py&lt;/em&gt; and included in &lt;a class="reference external" href="https://github.com/openstack/tripleo-heat-templates"&gt;tripleo-heat-templates&lt;/a&gt;, which allows for example for scaling of the resources definition, is currently going to be removed and replaced with code living entirely in &lt;a class="reference external" href="https://wiki.openstack.org/wiki/Heat"&gt;Heat&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;And there is more so once you tried, join us on #tripleo &amp;#64; freenode for the real fun!&lt;/p&gt;
</summary><category term="openstack"></category><category term="tripleo"></category><category term="high availability"></category><category term="meetup"></category><category term="fedoraplanet"></category></entry></feed>